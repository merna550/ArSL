{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d68244",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "import arabic_reshaper\n",
    "import cv2\n",
    "from bidi.algorithm import get_display\n",
    "from deep_translator import GoogleTranslator\n",
    "from ultralytics import YOLO\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "yolo_model = YOLO(\"/Users/mernaziad/Desktop/final_train/runs/detect/train/weights/best.pt\")\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "font_face = cv2.FONT_HERSHEY_SIMPLEX\n",
    "font_color = (0, 255, 0)\n",
    "thickness = 2\n",
    "font_path = \"/Users/mernaziad/PycharmProjects/GraduationProject/arabic_font.ttf\"\n",
    "font_size = 32  # Adjust the font size as needed\n",
    "# Set the font properties\n",
    "font_scale = 1\n",
    "font_thickness = 2\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "\n",
    "def translate_to_arabic(text):\n",
    "    \"\"\"\n",
    "    This function translate the text from detected language to arabic\n",
    "    :param text:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return GoogleTranslator(source='auto', target='ar').translate(text.lower())\n",
    "\n",
    "\n",
    "def convert_text_to_image(text, background_color=(255, 255, 255)):\n",
    "    # Create a PIL image with the specified background color\n",
    "    image = Image.new('RGB', (100, 100), background_color)\n",
    "\n",
    "    # Load the specified font\n",
    "    font = ImageFont.truetype(font_path, font_size)\n",
    "\n",
    "    # Create a PIL image draw object\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    # Calculate the text size\n",
    "    text_width, text_height = draw.textsize(text, font=font)\n",
    "\n",
    "    # Calculate the position to place the text in the middle of the image\n",
    "    text_x = (image.width - text_width) // 2\n",
    "    text_y = (image.height - text_height) // 2\n",
    "\n",
    "    # Draw the text on the image\n",
    "    draw.text((text_x, text_y), text, font=font, fill=font_color)\n",
    "\n",
    "    # Convert the PIL image to a NumPy array\n",
    "    image_array = np.array(image)\n",
    "\n",
    "    return image_array\n",
    "\n",
    "\n",
    "def get_arabic_text(text):\n",
    "    \"\"\"\n",
    "    This function converts arabic text on the frame\n",
    "\n",
    "    :param text:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    reshaped_text = arabic_reshaper.reshape(text)  # correct its shape\n",
    "    bidi_text = get_display(reshaped_text)  # correct its direction\n",
    "    return bidi_text\n",
    "\n",
    "\n",
    "def overlay_text_on_frame(frame, text_image):\n",
    "    # Calculate the position to place the text image in the middle of the frame\n",
    "    x = (frame.shape[1] - text_image.shape[1]) // 2\n",
    "    y = (frame.shape[0] - text_image.shape[0]) // 2\n",
    "\n",
    "    # Overlay the text image on the frame\n",
    "    frame[y:y + text_image.shape[0], x:x + text_image.shape[1]] = text_image\n",
    "\n",
    "    return frame\n",
    "\n",
    "\n",
    "def detect_objects(frame):\n",
    "    \"\"\"\n",
    "    This function detects the objects from the camera and sent it to the yolo model to extract the objects\n",
    "    about of it.\n",
    "    :param frame:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # Perform YOLO object detection on the frame\n",
    "    results = yolo_model.predict(frame)\n",
    "    result = results[0]\n",
    "    frame_with_text = frame\n",
    "    # Process the results and draw bounding boxes\n",
    "    for box in results[0].boxes:\n",
    "        cords = box.xyxy[0].tolist()\n",
    "        cords = [round(x) for x in cords]\n",
    "        class_id = result.names[box.cls[0].item()]\n",
    "        translated_text = translate_to_arabic(class_id)\n",
    "        expected_text = get_arabic_text(translated_text)\n",
    "\n",
    "        conf = round(box.conf[0].item(), 2)\n",
    "        logging.info(\"Object type:{} {}\".format(expected_text, class_id))\n",
    "        logging.info(\"Coordinates: {}\".format(cords))\n",
    "        logging.info(\"Probability: {}\".format(conf))\n",
    "\n",
    "        if conf < 0.5:\n",
    "            return\n",
    "\n",
    "        # text_size, _ = cv2.getTextSize(expected_text, font_face, font_scale, thickness)\n",
    "        # text_width, text_height = text_size\n",
    "        #\n",
    "        # x = int((frame.shape[1] - text_width) / 2)  # Center x-coordinate\n",
    "        # y = frame.shape[0] - 10  # Bottom margin\n",
    "\n",
    "        text_image = convert_text_to_image(expected_text)\n",
    "        frame_with_text = overlay_text_on_frame(frame, text_image)\n",
    "\n",
    "    # Display the modified frame\n",
    "    cv2.imshow(\"Object Detection\", frame_with_text)\n",
    "\n",
    "\n",
    "def process_frames():\n",
    "    ret, frame = cap.read()\n",
    "    if frame.shape[:2] != (800, 600):\n",
    "        frame = cv2.resize(frame, (800, 600))\n",
    "    # Perform object detection and modification on the frame\n",
    "    detect_objects(frame)\n",
    "    # Break the loop if 'q' is pressed\n",
    "\n",
    "\n",
    "while True:\n",
    "    process_frames()\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# executor = concurrent.futures.ThreadPoolExecutor(max_workers=2)\n",
    "# # Submit the process_frames function to the executor\n",
    "# executor.submit(process_frames)\n",
    "# # Wait for the 'q' key to be pressed\n",
    "# while cv2.waitKey(1) & 0xFF != ord('q'):\n",
    "#     pass\n",
    "#\n",
    "# # Shutdown the executor\n",
    "# executor.shutdown()\n",
    "\n",
    "# Release the video capture and close the window\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d2270c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "import arabic_reshaper\n",
    "import cv2\n",
    "from bidi.algorithm import get_display\n",
    "from ultralytics import YOLO\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "\n",
    "yolo_model = YOLO(\"/Users/mernaziad/Desktop/final_train/runs/detect/train/weights/best.pt\")\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "font_face = cv2.FONT_HERSHEY_SIMPLEX\n",
    "font_color = (255, 255, 255)\n",
    "thickness = 2\n",
    "font_path = \"/Users/mernaziad/PycharmProjects/GraduationProject/arabic_font.ttf\"\n",
    "font_size = 32  # Adjust the font size as needed\n",
    "# Set the font properties\n",
    "font_scale = 1\n",
    "font_thickness = 2\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "translation_dict = {\n",
    "    '0':'0',\n",
    "    '1':'1', \n",
    "    '2':'2', \n",
    "    '3':'3', \n",
    "    '4':'4', \n",
    "    '5':'5', \n",
    "    '6':'6', \n",
    "    '7':'7', \n",
    "    '8':'8', \n",
    "    '9':'9', \n",
    "    'ALIF':'أ', \n",
    "    'AYN':'ع', \n",
    "    'Atman lak 7aya sa3eeda' :'أتمنى لك حياة سعيدة', \n",
    "    'BAA':'ب', \n",
    "    'DAD':'ض', \n",
    "    'DELL':'د', \n",
    "    'DHAA':'ظ', \n",
    "    'DHELL':'ذ', \n",
    "    'FAA':'ف', \n",
    "    'GHAYN':'غ', \n",
    "    'HA':'هـ', \n",
    "    'HAA':'ح', \n",
    "    'JEEM':'ج', \n",
    "    'KAAF':'ك', \n",
    "    'KHAA':'خ', \n",
    "    'LAAM':'ل', \n",
    "    'MEEM':'م', \n",
    "    'QAAF':'ق', \n",
    "    'RAA':'ر', \n",
    "    'SAD':'ص', \n",
    "    'SEEN':'س', \n",
    "    'SHEEN':'ش', \n",
    "    'TA':'ت', \n",
    "    'TAA':'ط', \n",
    "    'THA':'ث', \n",
    "    'WAW':'و', \n",
    "    'YA':'ي', \n",
    "    'ZAY':'ز', \n",
    "    'bad':'سيء', \n",
    "    'del':'حذف', \n",
    "    'eqtibas':'اقتباس', \n",
    "    'good':'جيد', \n",
    "    'law sama7t':'لو سمحت', \n",
    "    'merhaba':'مرحبا', \n",
    "    'nothing':'لا شيء', \n",
    "    'o7ebok':'أحبك', \n",
    "    'oraqebak':'أراقبك', \n",
    "    'space':'مسافة', \n",
    "    'you':'أنت', \n",
    "}\n",
    " \n",
    "\n",
    "\n",
    "def translate_to_arabic(text):\n",
    "    if text in translation_dict:\n",
    "        return translation_dict[text]\n",
    "    else:\n",
    "        return text  # إذا لم تكن الكلمة موجودة في القاموس، استخدم النص الأصلي\n",
    "\n",
    "\n",
    "def convert_text_to_image(text, background_color=(0, 0, 0, 0)):\n",
    "    # Load the specified font\n",
    "    font = ImageFont.truetype(font_path, font_size)\n",
    "\n",
    "    # Create a new image with a transparent background\n",
    "    image = Image.new('RGBA', (1, 1), background_color)\n",
    "\n",
    "    # Create a draw object\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    # Calculate the text size\n",
    "    text_width, text_height = draw.textsize(text, font=font)\n",
    "\n",
    "    # Add some padding to the text size\n",
    "    padding = 10\n",
    "    image_width = text_width + padding\n",
    "    image_height = text_height + padding\n",
    "\n",
    "    # Create a new image with the adjusted dimensions and background color\n",
    "    image = Image.new('RGBA', (image_width, image_height), background_color)\n",
    "\n",
    "    # Create a new draw object with the adjusted image\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    # Calculate the position to place the text at the bottom of the image\n",
    "    text_x = (image.width - text_width) // 2\n",
    "    text_y = image.height - text_height - padding\n",
    "\n",
    "    # Draw the text on the image\n",
    "    draw.text((text_x, text_y), text, font=font, fill=font_color)\n",
    "\n",
    "    # Convert the PIL image to RGB mode\n",
    "    image = image.convert(\"RGB\")\n",
    "\n",
    "    # Convert the PIL image to a NumPy array\n",
    "    image_array = np.array(image)\n",
    "\n",
    "    return image_array\n",
    "\n",
    "def get_arabic_text(text):\n",
    "    reshaped_text = arabic_reshaper.reshape(text)\n",
    "    bidi_text = get_display(reshaped_text)\n",
    "    return bidi_text\n",
    "\n",
    "\n",
    "def overlay_text_on_frame(frame, text_image):\n",
    "    padding = 10\n",
    "    y = frame.shape[0] - text_image.shape[0] - padding\n",
    "    x = (frame.shape[1] - text_image.shape[1]) // 2\n",
    "    frame[y:y + text_image.shape[0], x:x + text_image.shape[1]] = text_image\n",
    "    \n",
    "\n",
    "    \n",
    "    return frame\n",
    "\n",
    "def detect_objects(frame):\n",
    "    results = yolo_model.predict(frame)\n",
    "    result = results[0]\n",
    "    frame_with_text = frame\n",
    "    for box in results[0].boxes:\n",
    "        cords = box.xyxy[0].tolist()\n",
    "        cords = [round(x) for x in cords]\n",
    "        class_id = result.names[box.cls[0].item()]\n",
    "        translated_text = translate_to_arabic(class_id)\n",
    "        expected_text = get_arabic_text(translated_text)\n",
    "\n",
    "        conf = round(box.conf[0].item(), 2)\n",
    "        logging.info(\"Object type:{} {}\".format(expected_text, class_id))\n",
    "        logging.info(\"Coordinates: {}\".format(cords))\n",
    "        logging.info(\"Probability: {}\".format(conf))\n",
    "\n",
    "        if conf < 0.5:\n",
    "            return\n",
    "\n",
    "        text_image = convert_text_to_image(expected_text)\n",
    "        frame_with_text = overlay_text_on_frame(frame, text_image)\n",
    "        \n",
    "        \n",
    "    # Display the modified frame\n",
    "    cv2.imshow(\"Object Detection\", frame_with_text)\n",
    "\n",
    "\n",
    "def process_frames():\n",
    "    ret, frame = cap.read()\n",
    "    if frame.shape[:2] != (800, 600):\n",
    "        frame = cv2.resize(frame, (800, 600))\n",
    "    # Perform object detection and modification on the frame\n",
    "    detect_objects(frame)\n",
    "    # Break the loop if 'q' is pressed\n",
    "\n",
    "\n",
    "while True:\n",
    "    process_frames()\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# executor = concurrent.futures.ThreadPoolExecutor(max_workers=2)\n",
    "# # Submit the process_frames function to the executor\n",
    "# executor.submit(process_frames)\n",
    "# # Wait for the 'q' key to be pressed\n",
    "# while cv2.waitKey(1) & 0xFF != ord('q'):\n",
    "#     pass\n",
    "#\n",
    "# # Shutdown the executor\n",
    "# executor.shutdown()\n",
    "\n",
    "# Release the video capture and close the window\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcbb76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import time\n",
    "\n",
    "import arabic_reshaper\n",
    "import cv2\n",
    "from bidi.algorithm import get_display\n",
    "from ultralytics import YOLO\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from gtts import gTTS\n",
    "import os\n",
    "\n",
    "yolo_model = YOLO(\"/Users/mernaziad/Desktop/final_train/runs/detect/train/weights/best.pt\")\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "font_face = cv2.FONT_HERSHEY_SIMPLEX\n",
    "font_color = (255, 255, 255)\n",
    "thickness = 2\n",
    "font_path = \"/Users/mernaziad/PycharmProjects/GraduationProject/arabic_font.ttf\"\n",
    "font_size = 32  # Adjust the font size as needed\n",
    "# Set the font properties\n",
    "font_scale = 1\n",
    "font_thickness = 2\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "translation_dict = {\n",
    "    '0':'0',\n",
    "    '1':'1', \n",
    "    '2':'2', \n",
    "    '3':'3', \n",
    "    '4':'4', \n",
    "    '5':'5', \n",
    "    '6':'6', \n",
    "    '7':'7', \n",
    "    '8':'8', \n",
    "    '9':'9', \n",
    "    'ALIF':'أ', \n",
    "    'AYN':'ع', \n",
    "    'Atman lak 7aya sa3eeda' :'أتمنى لك حياة سعيدة', \n",
    "    'BAA':'ب', \n",
    "    'DAD':'ض', \n",
    "    'DELL':'د', \n",
    "    'DHAA':'ظ', \n",
    "    'DHELL':'ذ', \n",
    "    'FAA':'ف', \n",
    "    'GHAYN':'غ', \n",
    "    'HA':'هـ', \n",
    "    'HAA':'ح', \n",
    "    'JEEM':'ج', \n",
    "    'KAAF':'ك', \n",
    "    'KHAA':'خ', \n",
    "    'LAAM':'ل', \n",
    "    'MEEM':'م', \n",
    "    'QAAF':'ق', \n",
    "    'RAA':'ر', \n",
    "    'SAD':'ص', \n",
    "    'SEEN':'س', \n",
    "    'SHEEN':'ش', \n",
    "    'TA':'ت', \n",
    "    'TAA':'ط', \n",
    "    'THA':'ث', \n",
    "    'WAW':'و', \n",
    "    'YA':'ي', \n",
    "    'ZAY':'ز', \n",
    "    'bad':'سيء', \n",
    "    'del':'حذف', \n",
    "    'eqtibas':'اقتباس', \n",
    "    'good':'جيد', \n",
    "    'law sama7t':'لو سمحت', \n",
    "    'merhaba':'مرحبا', \n",
    "    'nothing':'لا شيء', \n",
    "    'o7ebok':'أحبك', \n",
    "    'oraqebak':'أراقبك', \n",
    "    'space':'مسافة', \n",
    "    'you':'أنت', \n",
    "}\n",
    "\n",
    "# Time limit for word formation (in seconds)\n",
    "formation_time_limit = 1\n",
    "\n",
    "formed_word = \"\"  # Variable to store the formed word\n",
    "start_time = time.time()  # Variable to track the start time for word formation\n",
    "\n",
    "\n",
    "def translate_to_arabic(text):\n",
    "    if text in translation_dict:\n",
    "        return translation_dict[text]\n",
    "    else:\n",
    "        return text  # إذا لم تكن الكلمة موجودة في القاموس، استخدم النص الأصلي\n",
    "\n",
    "\n",
    "def convert_text_to_image(text, background_color=(0, 0, 0, 0)):\n",
    "    # Load the specified font\n",
    "    font = ImageFont.truetype(font_path, font_size)\n",
    "\n",
    "    # Create a new image with a transparent background\n",
    "    image = Image.new('RGBA', (1, 1), background_color)\n",
    "\n",
    "    # Create a draw object\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    # Calculate the text size\n",
    "    text_width, text_height = draw.textsize(text, font=font)\n",
    "\n",
    "    # Add some padding to the text size\n",
    "    padding = 10\n",
    "    image_width = text_width + padding\n",
    "    image_height = text_height + padding\n",
    "\n",
    "    # Create a new image with the adjusted dimensions and background color\n",
    "    image = Image.new('RGBA', (image_width, image_height), background_color)\n",
    "\n",
    "    # Create a new draw object with the adjusted image\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    # Calculate the position to place the text at the bottom of the image\n",
    "    text_x = (image.width - text_width) // 2\n",
    "    text_y = image.height - text_height - padding\n",
    "\n",
    "    # Draw the text on the image\n",
    "    draw.text((text_x, text_y), text, font=font, fill=font_color)\n",
    "\n",
    "    # Convert the PIL image to RGB mode\n",
    "    image = image.convert(\"RGB\")\n",
    "\n",
    "    # Convert the PIL image to a NumPy array\n",
    "    image_array = np.array(image)\n",
    "\n",
    "    return image_array\n",
    "\n",
    "def get_arabic_text(text):\n",
    "    reshaped_text = arabic_reshaper.reshape(text)\n",
    "    bidi_text = get_display(reshaped_text)\n",
    "    return bidi_text\n",
    "\n",
    "\n",
    "def overlay_text_on_frame(frame, text_image):\n",
    "    padding = 10\n",
    "    y = frame.shape[0] - text_image.shape[0] - padding\n",
    "    x = (frame.shape[1] - text_image.shape[1]) // 2\n",
    "    frame[y:y + text_image.shape[0], x:x + text_image.shape[1]] = text_image\n",
    "\n",
    "    return frame\n",
    "\n",
    "def detect_objects(frame):\n",
    "    global formed_word, start_time  # Indicate that we want to modify the global variables\n",
    "\n",
    "    results = yolo_model.predict(frame)\n",
    "    result = results[0]\n",
    "    frame_with_text = frame\n",
    "    texts_to_speak = []\n",
    "    for box in results[0].boxes:\n",
    "        cords = box.xyxy[0].tolist()\n",
    "        cords = [round(x) for x in cords]\n",
    "        class_id = result.names[box.cls[0].item()]\n",
    "        translated_text = translate_to_arabic(class_id)\n",
    "        expected_text = get_arabic_text(translated_text)\n",
    "\n",
    "        conf = round(box.conf[0].item(), 2)\n",
    "        logging.info(\"Object type:{} {}\".format(expected_text, class_id))\n",
    "        logging.info(\"Coordinates: {}\".format(cords))\n",
    "        logging.info(\"Probability: {}\".format(conf))\n",
    "\n",
    "        if conf < 0.8:\n",
    "            return        \n",
    "\n",
    "        text_image = convert_text_to_image(formed_word)\n",
    "        frame_with_text = overlay_text_on_frame(frame, text_image)\n",
    "\n",
    "#         # Convert the Arabic text to speech\n",
    "#         tts = gTTS(text=translated_text, lang='ar')\n",
    "#         audio_file = \"/Users/mernaziad/Desktop/text_to_speech.mp3\"\n",
    "#         tts.save(audio_file)\n",
    "\n",
    "#         # Play the Arabic text as speech\n",
    "#         os.system('mpg123 ' + audio_file)\n",
    "#         os.remove(audio_file)\n",
    "\n",
    "#         texts_to_speak.append(translated_text)\n",
    "        \n",
    "        # Add the detected word to the formed word\n",
    "        formed_word += expected_text\n",
    "\n",
    "        # Check if the formed word has reached the formation time limit\n",
    "        if time.time() - start_time >= formation_time_limit:\n",
    "            # Display the formed word\n",
    "            logging.info(\"Formed Word: {}\".format(formed_word))\n",
    "            \n",
    "            # Reset the formed word and start time\n",
    "            formed_word = \"\"\n",
    "            start_time = time.time()\n",
    "\n",
    "\n",
    "    # Display the modified frame\n",
    "    cv2.imshow(\"Object Detection\", frame_with_text)\n",
    "\n",
    "\n",
    "    \n",
    "def process_frames():\n",
    "    ret, frame = cap.read()\n",
    "    if frame.shape[:2] != (800, 600):\n",
    "        frame = cv2.resize(frame, (800, 600))\n",
    "    # Perform object detection and modification on the frame\n",
    "    detect_objects(frame)\n",
    "    # Break the loop if 'q' is pressed\n",
    "\n",
    "\n",
    "while True:\n",
    "    process_frames()\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture and close the window\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "##تجمييع"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8cda53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db202e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent\n",
    "import logging\n",
    "\n",
    "import arabic_reshaper\n",
    "import cv2\n",
    "from bidi.algorithm import get_display\n",
    "from deep_translator import GoogleTranslator\n",
    "from ultralytics import YOLO\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "yolo_model = YOLO(\"/Users/mernaziad/Downloads/yolo8/runs/detect/train/weights/best.pt\",\n",
    "                  \"/Users/mernaziad/Downloads/yolo8/datasets/Alphabets-1/data.yaml\")\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "font_face = cv2.FONT_HERSHEY_SIMPLEX\n",
    "font_color = (0, 255, 0)\n",
    "thickness = 2\n",
    "font_path = \"/Users/mernaziad/PycharmProjects/GraduationProject/arabic_font.ttf\"\n",
    "font_size = 32  # Adjust the font size as needed\n",
    "# Set the font properties\n",
    "font_scale = 1\n",
    "font_thickness = 2\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "\n",
    "def translate_to_arabic(text):\n",
    "    \"\"\"\n",
    "    This function translate the text from detected language to arabic\n",
    "    :param text:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return GoogleTranslator(source='auto', target='ar').translate(text.lower())\n",
    "\n",
    "\n",
    "def convert_text_to_image(text, background_color=(255, 255, 255)):\n",
    "    # Create a PIL image with the specified background color\n",
    "    image = Image.new('RGB', (100, 100), background_color)\n",
    "\n",
    "    # Load the specified font\n",
    "    font = ImageFont.truetype(font_path, font_size)\n",
    "\n",
    "    # Create a PIL image draw object\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    # Calculate the text size\n",
    "    text_width, text_height = draw.textsize(text, font=font)\n",
    "\n",
    "    # Calculate the position to place the text in the middle of the image\n",
    "    text_x = (image.width - text_width) // 2\n",
    "    text_y = (image.height - text_height) // 2\n",
    "\n",
    "    # Draw the text on the image\n",
    "    draw.text((text_x, text_y), text, font=font, fill=font_color)\n",
    "\n",
    "    # Convert the PIL image to a NumPy array\n",
    "    image_array = np.array(image)\n",
    "\n",
    "    return image_array\n",
    "\n",
    "\n",
    "def get_arabic_text(text):\n",
    "    \"\"\"\n",
    "    This function converts arabic text on the frame\n",
    "\n",
    "    :param text:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    reshaped_text = arabic_reshaper.reshape(text)  # correct its shape\n",
    "    bidi_text = get_display(reshaped_text)  # correct its direction\n",
    "    return bidi_text\n",
    "\n",
    "\n",
    "def overlay_text_on_frame(frame, text_image):\n",
    "    # Calculate the position to place the text image in the middle of the frame\n",
    "    x = (frame.shape[1] - text_image.shape[1]) // 2\n",
    "    y = (frame.shape[0] - text_image.shape[0]) // 2\n",
    "\n",
    "    # Overlay the text image on the frame\n",
    "    frame[y:y + text_image.shape[0], x:x + text_image.shape[1]] = text_image\n",
    "\n",
    "    return frame\n",
    "\n",
    "\n",
    "def detect_objects(frame):\n",
    "    \"\"\"\n",
    "    This function detects the objects from the camera and sent it to the yolo model to extract the objects\n",
    "    about of it.\n",
    "    :param frame:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # Perform YOLO object detection on the frame\n",
    "    results = yolo_model.predict(frame)\n",
    "    result = results[0]\n",
    "    frame_with_text = frame\n",
    "    # Process the results and draw bounding boxes\n",
    "    for box in results[0].boxes:\n",
    "        cords = box.xyxy[0].tolist()\n",
    "        cords = [round(x) for x in cords]\n",
    "        class_id = result.names[box.cls[0].item()]\n",
    "        translated_text = translate_to_arabic(class_id)\n",
    "        expected_text = get_arabic_text(translated_text)\n",
    "\n",
    "        conf = round(box.conf[0].item(), 2)\n",
    "        logging.info(\"Object type:{} {}\".format(expected_text, class_id))\n",
    "        logging.info(\"Coordinates: {}\".format(cords))\n",
    "        logging.info(\"Probability: {}\".format(conf))\n",
    "\n",
    "        if conf < 0.5:\n",
    "            return\n",
    "\n",
    "        # text_size, _ = cv2.getTextSize(expected_text, font_face, font_scale, thickness)\n",
    "        # text_width, text_height = text_size\n",
    "        #\n",
    "        # x = int((frame.shape[1] - text_width) / 2)  # Center x-coordinate\n",
    "        # y = frame.shape[0] - 10  # Bottom margin\n",
    "\n",
    "        text_image = convert_text_to_image(expected_text)\n",
    "        frame_with_text = overlay_text_on_frame(frame, text_image)\n",
    "\n",
    "    # Display the modified frame\n",
    "    cv2.imshow(\"Object Detection\", frame_with_text)\n",
    "\n",
    "\n",
    "def process_frames():\n",
    "    ret, frame = cap.read()\n",
    "    if frame.shape[:2] != (800, 600):\n",
    "        frame = cv2.resize(frame, (800, 600))\n",
    "    # Perform object detection and modification on the frame\n",
    "    detect_objects(frame)\n",
    "    # Break the loop if 'q' is pressed\n",
    "\n",
    "\n",
    "while True:\n",
    "    process_frames()\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# executor = concurrent.futures.ThreadPoolExecutor(max_workers=4)\n",
    "# # Submit the process_frames function to the executor\n",
    "# executor.submit(process_frames)\n",
    "# # Wait for the 'q' key to be pressed\n",
    "# while cv2.waitKey(1) & 0xFF != ord('q'):\n",
    "#     pass\n",
    "\n",
    "# # Shutdown the executor\n",
    "# executor.shutdown()\n",
    "\n",
    "# Release the video capture and close the window\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595e37de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import time\n",
    "\n",
    "import arabic_reshaper\n",
    "import cv2\n",
    "from bidi.algorithm import get_display\n",
    "from ultralytics import YOLO\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from gtts import gTTS\n",
    "import os\n",
    "\n",
    "yolo_model = YOLO(\"/Users/mernaziad/Desktop/final_train/runs/detect/train/weights/best.pt\")\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "font_face = cv2.FONT_HERSHEY_SIMPLEX\n",
    "font_color = (255, 255, 255)\n",
    "thickness = 2\n",
    "font_path = \"/path/to/arabic_font.ttf\"\n",
    "font_size = 32  # Adjust the font size as needed\n",
    "# Set the font properties\n",
    "font_scale = 1\n",
    "font_thickness = 2\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "translation_dict = {\n",
    "    '0': '0',\n",
    "    '1': '1',\n",
    "    '2': '2',\n",
    "    '3': '3',\n",
    "    '4': '4',\n",
    "    '5': '5',\n",
    "    '6': '6',\n",
    "    '7': '7',\n",
    "    '8': '8',\n",
    "    '9': '9',\n",
    "    'ALIF': 'أ',\n",
    "    'AYN': 'ع',\n",
    "    'Atman lak 7aya sa3eeda': 'أتمنى لك حياة سعيدة',\n",
    "    'BAA': 'ب',\n",
    "    'DAD': 'ض',\n",
    "    'DELL': 'د',\n",
    "    'DHAA': 'ظ',\n",
    "    'DHELL': 'ذ',\n",
    "    'FAA': 'ف',\n",
    "    'GHAYN': 'غ',\n",
    "    'HA': 'هـ',\n",
    "    'HAA': 'ح',\n",
    "    'JEEM': 'ج',\n",
    "    'KAAF': 'ك',\n",
    "    'KHAA': 'خ',\n",
    "    'LAAM': 'ل',\n",
    "    'MEEM': 'م',\n",
    "    'QAAF': 'ق',\n",
    "    'RAA': 'ر',\n",
    "    'SAD': 'ص',\n",
    "    'SEEN': 'س',\n",
    "    'SHEEN': 'ش',\n",
    "    'TA': 'ت',\n",
    "    'TAA': 'ط',\n",
    "    'THA': 'ث',\n",
    "    'WAW': 'و',\n",
    "    'YA': 'ي',\n",
    "    'ZAY': 'ز',\n",
    "    'bad': 'سيء',\n",
    "    'del': 'حذف',\n",
    "    'eqtibas': 'اقتباس',\n",
    "    'good': 'جيد',\n",
    "    'law sama7t': 'لو سمحت',\n",
    "    'merhaba': 'مرحبا',\n",
    "    'nothing': 'لا شيء',\n",
    "    'o7ebok': 'أحبك',\n",
    "    'oraqebak': 'أراقبك',\n",
    "    'space': 'مسافة',\n",
    "    'you': 'أنت',\n",
    "}\n",
    "\n",
    "# Time limit for word formation (in seconds)\n",
    "formation_time_limit = 5\n",
    "\n",
    "formed_word = \"\"  # Variable to store the formed word\n",
    "start_time = time.time()  # Variable to track the start time for word formation\n",
    "\n",
    "\n",
    "def translate_to_arabic(text):\n",
    "    if text in translation_dict:\n",
    "        return translation_dict[text]\n",
    "    else:\n",
    "        return text  # إذا لم تكن الكلمة موجودة في القاموس، استخدم النص الأصلي\n",
    "\n",
    "\n",
    "def convert_text_to_image(text, background_color=(0, 0, 0, 0)):\n",
    "    # Load the specified font\n",
    "    font = ImageFont.truetype(font_path, font_size)\n",
    "\n",
    "    # Create a new image with a transparent background\n",
    "    image = Image.new('RGBA', (1, 1), background_color)\n",
    "\n",
    "    # Create a draw object\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    # Calculate the text size\n",
    "    text_width, text_height = draw.textsize(text, font=font)\n",
    "\n",
    "    # Add some padding to the text size\n",
    "    padding = 10\n",
    "    image_width = text_width + padding\n",
    "    image_height = text_height + padding\n",
    "\n",
    "    # Create a new image with the adjusted dimensions and background color\n",
    "    image = Image.new('RGBA', (image_width, image_height), background_color)\n",
    "\n",
    "    # Create a new draw object with the adjusted image\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    # Calculate the position to place the text at the bottom of the image\n",
    "    text_x = (image.width - text_width) // 2\n",
    "    text_y = image.height - text_height - padding\n",
    "\n",
    "    # Draw the text on the image\n",
    "    draw.text((text_x, text_y), text, font=font, fill=font_color)\n",
    "\n",
    "    # Convert the PIL image to RGB mode\n",
    "    image = image.convert(\"RGB\")\n",
    "\n",
    "    # Convert the PIL image to a NumPy array\n",
    "    image_array = np.array(image)\n",
    "\n",
    "    return image_array\n",
    "\n",
    "\n",
    "def get_arabic_text(text):\n",
    "    reshaped_text = arabic_reshaper.reshape(text)\n",
    "    bidi_text = get_display(reshaped_text)\n",
    "    return bidi_text\n",
    "\n",
    "\n",
    "def overlay_text_on_frame(frame, text_image):\n",
    "    padding = 10\n",
    "    y = frame.shape[0] - text_image.shape[0] - padding\n",
    "    x = (frame.shape[1] - text_image.shape[1]) // 2\n",
    "    frame[y:y + text_image.shape[0], x:x + text_image.shape[1]] = text_image\n",
    "\n",
    "    return frame\n",
    "\n",
    "\n",
    "def detect_objects(frame):\n",
    "    global formed_word, start_time  # Indicate that we want to modify the global variables\n",
    "\n",
    "    results = yolo_model.predict(frame)\n",
    "    result = results[0]\n",
    "    frame_with_text = frame\n",
    "    texts_to_speak = []\n",
    "    for box in results[0].boxes:\n",
    "        cords = box.xyxy[0].tolist()\n",
    "        cords = [round(x) for x in cords]\n",
    "        class_id = result.names[box.cls[0].item()]\n",
    "        translated_text = translate_to_arabic(class_id)\n",
    "        expected_text = get_arabic_text(translated_text)\n",
    "\n",
    "        conf = round(box.conf[0].item(), 2)\n",
    "        logging.info(\"Object type:{} {}\".format(expected_text, class_id))\n",
    "        logging.info(\"Coordinates: {}\".format(cords))\n",
    "        logging.info(\"Probability: {}\".format(conf))\n",
    "\n",
    "        if conf < 0.5:\n",
    "            return\n",
    "\n",
    "        text_image = convert_text_to_image(formed_word)\n",
    "        frame_with_text = overlay_text_on_frame(frame, text_image)\n",
    "\n",
    "        # Convert the Arabic text to speech\n",
    "        tts = gTTS(text=translated_text, lang='ar')\n",
    "        audio_file = \"/path/to/text_to_speech.mp3\"\n",
    "        tts.save(audio_file)\n",
    "\n",
    "        # Play the Arabic text as speech\n",
    "        os.system('mpg123 ' + audio_file)\n",
    "        os.remove(audio_file)\n",
    "\n",
    "        texts_to_speak.append(translated_text)\n",
    "\n",
    "        # Add the detected word to the formed word\n",
    "        formed_word += expected_text\n",
    "\n",
    "       \n",
    "        # Check if the time limit for word formation has exceeded\n",
    "        elapsed_time = time.time() - start_time\n",
    "        if elapsed_time >= formation_time_limit:\n",
    "            logging.info(\"Formed Word: {}\".format(formed_word))\n",
    "            formed_word = \"\"\n",
    "            start_time = time.time()\n",
    "\n",
    "    # Display the formed word on the frame\n",
    "    text_image = convert_text_to_image(formed_word)\n",
    "    frame_with_text = overlay_text_on_frame(frame, text_image)\n",
    "\n",
    "    return frame_with_text, texts_to_speak\n",
    "\n",
    "\n",
    "def main():\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Resize the frame to a suitable size for processing\n",
    "        resized_frame = cv2.resize(frame, (640, 480))\n",
    "\n",
    "        # Convert the frame from BGR to RGB\n",
    "        rgb_frame = cv2.cvtColor(resized_frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Detect objects and overlay text on the frame\n",
    "        processed_frame, texts_to_speak = detect_objects(rgb_frame)\n",
    "\n",
    "        # Convert the frame back to BGR for display\n",
    "        bgr_frame = cv2.cvtColor(processed_frame, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # Display the frame\n",
    "        cv2.imshow(\"Frame\", bgr_frame)\n",
    "\n",
    "        # Exit the loop if 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release the video capture and destroy the windows\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88095364",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import time\n",
    "import arabic_reshaper\n",
    "import cv2\n",
    "from bidi.algorithm import get_display\n",
    "from ultralytics import YOLO\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from gtts import gTTS\n",
    "import os\n",
    "\n",
    "yolo_model = YOLO(\"/Users/mernaziad/Desktop/final_train/runs/detect/train/weights/best.pt\")\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "font_face = cv2.FONT_HERSHEY_SIMPLEX\n",
    "font_color = (255, 255, 255)\n",
    "thickness = 2\n",
    "font_path = \"/Users/mernaziad/PycharmProjects/GraduationProject/arabic_font.ttf\"\n",
    "font_size = 32  # Adjust the font size as needed\n",
    "# Set the font properties\n",
    "font_scale = 1\n",
    "font_thickness = 2\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "translation_dict = {\n",
    "    '0':'0',\n",
    "    '1':'1', \n",
    "    '2':'2', \n",
    "    '3':'3', \n",
    "    '4':'4', \n",
    "    '5':'5', \n",
    "    '6':'6', \n",
    "    '7':'7', \n",
    "    '8':'8', \n",
    "    '9':'9', \n",
    "    'ALIF':'أ', \n",
    "    'AYN':'ع', \n",
    "    'Atman lak 7aya sa3eeda' :'أتمنى لك حياة سعيدة', \n",
    "    'BAA':'ب', \n",
    "    'DAD':'ض', \n",
    "    'DELL':'د', \n",
    "    'DHAA':'ظ', \n",
    "    'DHELL':'ذ', \n",
    "    'FAA':'ف', \n",
    "    'GHAYN':'غ', \n",
    "    'HA':'هـ', \n",
    "    'HAA':'ح', \n",
    "    'JEEM':'ج', \n",
    "    'KAAF':'ك', \n",
    "    'KHAA':'خ', \n",
    "    'LAAM':'ل', \n",
    "    'MEEM':'م', \n",
    "    'QAAF':'ق', \n",
    "    'RAA':'ر', \n",
    "    'SAD':'ص', \n",
    "    'SEEN':'س', \n",
    "    'SHEEN':'ش', \n",
    "    'TA':'ت', \n",
    "    'TAA':'ط', \n",
    "    'THA':'ث', \n",
    "    'WAW':'و', \n",
    "    'YA':'ي', \n",
    "    'ZAY':'ز', \n",
    "    'bad':'سيء', \n",
    "    'del':'حذف', \n",
    "    'eqtibas':'اقتباس', \n",
    "    'good':'جيد', \n",
    "    'law sama7t':'لو سمحت', \n",
    "    'merhaba':'مرحبا', \n",
    "    'nothing':'لا شيء', \n",
    "    'o7ebok':'أحبك', \n",
    "    'oraqebak':'أراقبك', \n",
    "    'space':'مسافة', \n",
    "    'you':'أنت', \n",
    "}\n",
    "\n",
    "# # Time limit for word formation (in seconds)\n",
    "# formation_time_limit = 5\n",
    "\n",
    "# formed_word = \"\"  # Variable to store the formed word\n",
    "# start_time = time.time()  # Variable to track the start time for word formation\n",
    "\n",
    "\n",
    "def translate_to_arabic(text):\n",
    "    if text in translation_dict:\n",
    "        return translation_dict[text]\n",
    "    else:\n",
    "        return text  # إذا لم تكن الكلمة موجودة في القاموس، استخدم النص الأصلي\n",
    "\n",
    "\n",
    "def convert_text_to_image(text, background_color=(0, 0, 0, 0)):\n",
    "    # Load the specified font\n",
    "    font = ImageFont.truetype(font_path, font_size)\n",
    "\n",
    "    # Create a new image with a transparent background\n",
    "    image = Image.new('RGBA', (1, 1), background_color)\n",
    "\n",
    "    # Create a draw object\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    # Calculate the text size\n",
    "    text_width, text_height = draw.textsize(text, font=font)\n",
    "\n",
    "    # Add some padding to the text size\n",
    "    padding = 10\n",
    "    image_width = text_width + padding\n",
    "    image_height = text_height + padding\n",
    "\n",
    "    # Create a new image with the adjusted dimensions and background color\n",
    "    image = Image.new('RGBA', (image_width, image_height), background_color)\n",
    "\n",
    "    # Create a new draw object with the adjusted image\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    # Calculate the position to place the text at the bottom of the image\n",
    "    text_x = (image.width - text_width) // 2\n",
    "    text_y = image.height - text_height - padding\n",
    "\n",
    "    # Draw the text on the image\n",
    "    draw.text((text_x, text_y), text, font=font, fill=font_color)\n",
    "\n",
    "    # Convert the PIL image to RGB mode\n",
    "    image = image.convert(\"RGB\")\n",
    "\n",
    "    # Convert the PIL image to a NumPy array\n",
    "    image_array = np.array(image)\n",
    "\n",
    "    return image_array\n",
    "\n",
    "def get_arabic_text(text):\n",
    "    reshaped_text = arabic_reshaper.reshape(text)\n",
    "    bidi_text = get_display(reshaped_text)\n",
    "    return bidi_text\n",
    "\n",
    "\n",
    "def overlay_text_on_frame(frame, text_image):\n",
    "    padding = 10\n",
    "    y = frame.shape[0] - text_image.shape[0] - padding\n",
    "    x = (frame.shape[1] - text_image.shape[1]) // 2\n",
    "    frame[y:y + text_image.shape[0], x:x + text_image.shape[1]] = text_image\n",
    "\n",
    "    return frame\n",
    "\n",
    "# Define variables for word formation\n",
    "formation_time_limit = 2  # Time limit for word formation in seconds\n",
    "formed_word = \"\"  # Variable to store the formed word\n",
    "start_time = time.time()  # Variable to track the start time for word formation\n",
    "\n",
    "def detect_objects(frame):\n",
    "    global formed_word, start_time  # Indicate that we want to modify the global variables\n",
    "\n",
    "    results = yolo_model.predict(frame)\n",
    "    result = results[0]\n",
    "    frame_with_text = frame\n",
    "    texts_to_speak = []\n",
    "    for box in results[0].boxes:\n",
    "        cords = box.xyxy[0].tolist()\n",
    "        cords = [round(x) for x in cords]\n",
    "        class_id = result.names[box.cls[0].item()]\n",
    "        translated_text = translate_to_arabic(class_id)\n",
    "        expected_text = get_arabic_text(translated_text)\n",
    "\n",
    "        conf = round(box.conf[0].item(), 2)\n",
    "        logging.info(\"Object type:{} {}\".format(expected_text, class_id))\n",
    "        logging.info(\"Coordinates: {}\".format(cords))\n",
    "        logging.info(\"Probability: {}\".format(conf))\n",
    "\n",
    "        if conf < 0.5:\n",
    "            return        \n",
    "\n",
    "        text_image = convert_text_to_image(expected_text)\n",
    "        frame_with_text = overlay_text_on_frame(frame, text_image)\n",
    "\n",
    "        # Convert the Arabic text to speech\n",
    "        tts = gTTS(text=translated_text, lang='ar')\n",
    "        audio_file = \"/Users/mernaziad/Desktop/text_to_speech.mp3\"\n",
    "        tts.save(audio_file)\n",
    "\n",
    "        # Play the Arabic text as speech\n",
    "        os.system('mpg123 ' + audio_file)\n",
    "        os.remove(audio_file)\n",
    "\n",
    "        texts_to_speak.append(translated_text)\n",
    "        \n",
    "\n",
    "    # Display the modified frame\n",
    "    cv2.imshow(\"Object Detection\", frame_with_text)\n",
    "\n",
    "\n",
    "    \n",
    "def process_frames():\n",
    "    ret, frame = cap.read()\n",
    "    if frame.shape[:2] != (800, 600):\n",
    "        frame = cv2.resize(frame, (800, 600))\n",
    "\n",
    "    # Perform object detection and modification on the frame\n",
    "    detect_objects(frame)\n",
    "    # Break the loop if 'q' is pressed\n",
    "\n",
    "\n",
    "while True:\n",
    "    process_frames()\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture and close the window\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d623722",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import time\n",
    "import arabic_reshaper\n",
    "import cv2\n",
    "from bidi.algorithm import get_display\n",
    "from ultralytics import YOLO\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from gtts import gTTS\n",
    "import os\n",
    "\n",
    "yolo_model = YOLO(\"/Users/mernaziad/Desktop/final_train/runs/detect/train/weights/best.pt\")\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "font_face = cv2.FONT_HERSHEY_SIMPLEX\n",
    "font_color = (255, 255, 255)\n",
    "thickness = 2\n",
    "font_path = \"/Users/mernaziad/PycharmProjects/GraduationProject/arabic_font.ttf\"\n",
    "font_size = 32  # Adjust the font size as needed\n",
    "# Set the font properties\n",
    "font_scale = 1\n",
    "font_thickness = 2\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "translation_dict = {\n",
    "    '0':'0',\n",
    "    '1':'1', \n",
    "    '2':'2', \n",
    "    '3':'3', \n",
    "    '4':'4', \n",
    "    '5':'5', \n",
    "    '6':'6', \n",
    "    '7':'7', \n",
    "    '8':'8', \n",
    "    '9':'9', \n",
    "    'ALIF':'أ', \n",
    "    'AYN':'ع', \n",
    "    'Atman lak 7aya sa3eeda' :'أتمنى لك حياة سعيدة', \n",
    "    'BAA':'ب', \n",
    "    'DAD':'ض', \n",
    "    'DELL':'د', \n",
    "    'DHAA':'ظ', \n",
    "    'DHELL':'ذ', \n",
    "    'FAA':'ف', \n",
    "    'GHAYN':'غ', \n",
    "    'HA':'هـ', \n",
    "    'HAA':'ح', \n",
    "    'JEEM':'ج', \n",
    "    'KAAF':'ك', \n",
    "    'KHAA':'خ', \n",
    "    'LAAM':'ل', \n",
    "    'MEEM':'م', \n",
    "    'QAAF':'ق', \n",
    "    'RAA':'ر', \n",
    "    'SAD':'ص', \n",
    "    'SEEN':'س', \n",
    "    'SHEEN':'ش', \n",
    "    'TA':'ت', \n",
    "    'TAA':'ط', \n",
    "    'THA':'ث', \n",
    "    'WAW':'و', \n",
    "    'YA':'ي', \n",
    "    'ZAY':'ز', \n",
    "    'bad':'سيء', \n",
    "    'del':'حذف', \n",
    "    'eqtibas':'اقتباس', \n",
    "    'good':'جيد', \n",
    "    'law sama7t':'لو سمحت', \n",
    "    'merhaba':'مرحبا', \n",
    "    'nothing':'لا شيء', \n",
    "    'o7ebok':'أحبك', \n",
    "    'oraqebak':'أراقبك', \n",
    "    'space':'مسافة', \n",
    "    'you':'أنت', \n",
    "}\n",
    "\n",
    "# Variables for word formation\n",
    "formation_time_limit = 2  # Time limit for word formation in seconds\n",
    "formed_word = \"\"  # Variable to store the formed word\n",
    "start_time = time.time()  # Variable to track the start time for word formation\n",
    "previous_character = \"\"  # Variable to store the previous character\n",
    "\n",
    "def translate_to_arabic(text):\n",
    "    if text in translation_dict:\n",
    "        return translation_dict[text]\n",
    "    else:\n",
    "        return text  # إذا لم تكن الكلمة موجودة في القاموس، استخدم النص الأصلي\n",
    "\n",
    "\n",
    "def convert_text_to_image(text, background_color=(0, 0, 0, 0)):\n",
    "    # Load the specified font\n",
    "    font = ImageFont.truetype(font_path, font_size)\n",
    "\n",
    "    # Create a new image with a transparent background\n",
    "    image = Image.new('RGBA', (1, 1), background_color)\n",
    "\n",
    "    # Create a draw object\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    # Calculate the text size\n",
    "    text_width, text_height = draw.textsize(text, font=font)\n",
    "\n",
    "    # Add some padding to the text size\n",
    "    padding = 10\n",
    "    image_width = text_width + padding\n",
    "    image_height = text_height + padding\n",
    "\n",
    "    # Create a new image with the adjusted dimensions and background color\n",
    "    image = Image.new('RGBA', (image_width, image_height), background_color)\n",
    "\n",
    "    # Create a new draw object with the adjusted image\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    # Calculate the position to place the text at the bottom of the image\n",
    "    text_x = (image.width - text_width) // 2\n",
    "    text_y = image.height - text_height - padding\n",
    "\n",
    "    # Draw the text on the image\n",
    "    draw.text((text_x, text_y), text, font=font, fill=font_color)\n",
    "\n",
    "    # Convert the PIL image to RGB mode\n",
    "    image = image.convert(\"RGB\")\n",
    "\n",
    "    # Convert the PIL image to a NumPy array\n",
    "    image_array = np.array(image)\n",
    "\n",
    "    return image_array\n",
    "\n",
    "def get_arabic_text(text):\n",
    "    reshaped_text = arabic_reshaper.reshape(text)\n",
    "    bidi_text = get_display(reshaped_text)\n",
    "    return bidi_text\n",
    "\n",
    "\n",
    "def overlay_text_on_frame(frame, text_image):\n",
    "    padding = 10\n",
    "    y = frame.shape[0] - text_image.shape[0] - padding\n",
    "    x = (frame.shape[1] - text_image.shape[1]) // 2\n",
    "    frame[y:y + text_image.shape[0], x:x + text_image.shape[1]] = text_image\n",
    "\n",
    "    return frame\n",
    "\n",
    "# Define variables for word formation\n",
    "formation_time_limit = 2  # Time limit for word formation in seconds\n",
    "formed_word = \"\"  # Variable to store the formed word\n",
    "start_time = time.time()  # Variable to track the start time for word formation\n",
    "\n",
    "def detect_objects(frame):\n",
    "    global formed_word, start_time  # Indicate that we want to modify the global variables\n",
    "\n",
    "    results = yolo_model.predict(frame)\n",
    "    result = results[0]\n",
    "    frame_with_text = frame\n",
    "    texts_to_speak = []\n",
    "    formed_word = \"\"  # Reset the formed word for each frame\n",
    "\n",
    "    for box in results[0].boxes:\n",
    "        cords = box.xyxy[0].tolist()\n",
    "        cords = [round(x) for x in cords]\n",
    "        class_id = result.names[box.cls[0].item()]\n",
    "        translated_text = translate_to_arabic(class_id)\n",
    "        expected_text = get_arabic_text(translated_text)\n",
    "\n",
    "        conf = round(box.conf[0].item(), 2)\n",
    "        logging.info(\"Object type:{} {}\".format(expected_text, class_id))\n",
    "        logging.info(\"Coordinates: {}\".format(cords))\n",
    "        logging.info(\"Probability: {}\".format(conf))\n",
    "\n",
    "        if conf < 0.5:\n",
    "            return        \n",
    "\n",
    "        text_image = convert_text_to_image(expected_text)\n",
    "        frame_with_text = overlay_text_on_frame(frame, text_image)\n",
    "\n",
    "        # Convert the Arabic text to speech\n",
    "        tts = gTTS(text=translated_text, lang='ar')\n",
    "        audio_file = \"/Users/mernaziad/Desktop/text_to_speech.mp3\"\n",
    "        tts.save(audio_file)\n",
    "\n",
    "        # Play the Arabic text as speech\n",
    "        os.system('mpg123 ' + audio_file)\n",
    "        os.remove(audio_file)\n",
    "        texts_to_speak.append(translated_text)\n",
    "\n",
    "\n",
    "    # Display the modified frame\n",
    "    cv2.imshow(\"Object Detection\", frame_with_text)\n",
    "\n",
    "\n",
    "    \n",
    "def process_frames():\n",
    "    ret, frame = cap.read()\n",
    "    if frame.shape[:2] != (800, 600):\n",
    "        frame = cv2.resize(frame, (800, 600))\n",
    "\n",
    "    # Perform object detection and modification on the frame\n",
    "    detect_objects(frame)\n",
    "    # Break the loop if 'q' is pressed\n",
    "\n",
    "\n",
    "while True:\n",
    "    process_frames()\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture and close the window\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce2792f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import time\n",
    "import arabic_reshaper\n",
    "import cv2\n",
    "from bidi.algorithm import get_display\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "yolo_model = YOLO(\"/Users/mernaziad/Desktop/final_train/runs/detect/train/weights/best.pt\")  # Replace with the path to your YOLO model weights\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Define the font properties\n",
    "font_face = cv2.FONT_HERSHEY_SIMPLEX\n",
    "font_color = (255, 255, 255)\n",
    "thickness = 2\n",
    "font_path = \"/Users/mernaziad/PycharmProjects/GraduationProject/arabic_font.ttf\"  # Replace with the path to your Arabic font file\n",
    "font_size = 32\n",
    "font_scale = 1\n",
    "font_thickness = 2\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Translation dictionary\n",
    "translation_dict = {\n",
    "    '0':'0',\n",
    "    '1':'1', \n",
    "    '2':'2', \n",
    "    '3':'3', \n",
    "    '4':'4', \n",
    "    '5':'5', \n",
    "    '6':'6', \n",
    "    '7':'7', \n",
    "    '8':'8', \n",
    "    '9':'9', \n",
    "    'ALIF':'أ', \n",
    "    'AYN':'ع', \n",
    "    'Atman lak 7aya sa3eeda' :'أتمنى لك حياة سعيدة', \n",
    "    'BAA':'ب', \n",
    "    'DAD':'ض', \n",
    "    'DELL':'د', \n",
    "    'DHAA':'ظ', \n",
    "    'DHELL':'ذ', \n",
    "    'FAA':'ف', \n",
    "    'GHAYN':'غ', \n",
    "    'HA':'هـ', \n",
    "    'HAA':'ح', \n",
    "    'JEEM':'ج', \n",
    "    'KAAF':'ك', \n",
    "    'KHAA':'خ', \n",
    "    'LAAM':'ل', \n",
    "    'MEEM':'م', \n",
    "    'QAAF':'ق', \n",
    "    'RAA':'ر', \n",
    "    'SAD':'ص', \n",
    "    'SEEN':'س', \n",
    "    'SHEEN':'ش', \n",
    "    'TA':'ت', \n",
    "    'TAA':'ط', \n",
    "    'THA':'ث', \n",
    "    'WAW':'و', \n",
    "    'YA':'ي', \n",
    "    'ZAY':'ز', \n",
    "    'bad':'سيء', \n",
    "    'del':'حذف', \n",
    "    'eqtibas':'اقتباس', \n",
    "    'good':'جيد', \n",
    "    'law sama7t':'لو سمحت', \n",
    "    'merhaba':'مرحبا', \n",
    "    'nothing':'لا شيء', \n",
    "    'o7ebok':'أحبك', \n",
    "    'oraqebak':'أراقبك', \n",
    "    'space':'مسافة', \n",
    "    'you':'أنت', \n",
    "}\n",
    "\n",
    "# Time limit for word formation (in seconds)\n",
    "formation_time_limit = 5\n",
    "\n",
    "formed_sentence = \"\"  # المتغير لتخزين الجملة المتكونة\n",
    "start_time = time.time()  # المتغير لتتبع وقت ظهور أول حرف في الجملة\n",
    "sentence_formation_time_limit = 5  # الوقت المسموح به لتجميع الجملة (بالثواني)\n",
    "\n",
    "def translate_to_arabic(text):\n",
    "    if text in translation_dict:\n",
    "        return translation_dict[text]\n",
    "    else:\n",
    "        return text  # If the word is not in the translation dictionary, use the original text\n",
    "\n",
    "def convert_text_to_image(text, background_color=(0, 0, 0, 0)):\n",
    "    # Load the specified font\n",
    "    font = ImageFont.truetype(font_path, font_size)\n",
    "\n",
    "    # Create a new image with a transparent background\n",
    "    image = Image.new('RGBA', (1, 1), background_color)\n",
    "\n",
    "    # Create a draw object\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    # Calculate the text size\n",
    "    text_width, text_height = draw.textsize(text, font=font)\n",
    "\n",
    "    # Add some padding to the text size\n",
    "    padding = 10\n",
    "    image_width = text_width + padding\n",
    "    image_height = text_height + padding\n",
    "\n",
    "    # Create a new image with the adjusted dimensions and background color\n",
    "    image = Image.new('RGBA', (image_width, image_height), background_color)\n",
    "\n",
    "    # Create a new draw object with the adjusted image\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    # Calculate the position to place the text at the bottom of the image\n",
    "    text_x = (image.width - text_width) // 2\n",
    "    text_y = image.height - text_height - padding\n",
    "\n",
    "    # Draw the text on the image\n",
    "    draw.text((text_x, text_y), text, font=font, fill=font_color)\n",
    "\n",
    "    # Convert the PIL image to RGB mode\n",
    "    image = image.convert(\"RGB\")\n",
    "\n",
    "    # Convert the PIL image to a NumPy array\n",
    "    image_array = np.array(image)\n",
    "\n",
    "    return image_array\n",
    "\n",
    "def get_arabic_text(text):\n",
    "    reshaped_text = arabic_reshaper.reshape(text)\n",
    "    bidi_text = get_display(reshaped_text)\n",
    "    return bidi_text\n",
    "\n",
    "def overlay_text_on_frame(frame, text_image):\n",
    "    padding = 10\n",
    "    y = frame.shape[0] - text_image.shape[0] - padding\n",
    "    x = (frame.shape[1] - text_image.shape[1]) // 2\n",
    "    frame[y:y + text_image.shape[0], x:x + text_image.shape[1]] = text_image\n",
    "\n",
    "    return frame\n",
    "\n",
    "def detect_objects(frame):\n",
    "    global formed_sentence, start_time  # Indicate that we want to modify the global variables\n",
    "\n",
    "    results = yolo_model.predict(frame)\n",
    "    result = results[0]\n",
    "    frame_with_text = frame\n",
    "    texts_to_speak = []\n",
    "\n",
    "    for box in results[0].boxes:\n",
    "        cords = box.xyxy[0].tolist()\n",
    "        cords = [round(x) for x in cords]\n",
    "        class_id = result.names[box.cls[0].item()]\n",
    "        translated_text = translate_to_arabic(class_id)\n",
    "        expected_text = get_arabic_text(translated_text)\n",
    "\n",
    "        conf = round(box.conf[0].item(), 2)\n",
    "        logging.info(\"Object type:{} {}\".format(expected_text, class_id))\n",
    "        logging.info(\"Coordinates: {}\".format(cords))\n",
    "        logging.info(\"Probability: {}\".format(conf))\n",
    "\n",
    "        if conf < 0.5:\n",
    "            continue\n",
    "\n",
    "        text_image = convert_text_to_image(expected_text)\n",
    "        frame_with_text = overlay_text_on_frame(frame, text_image)\n",
    "\n",
    "        if translated_text != \"\":  # التأكد من وجود حرف مترجم\n",
    "            formed_sentence += translated_text  # إضافة الحرف المترجم إلى الجملة المتكونة\n",
    "\n",
    "            elapsed_time = time.time() - start_time  # حساب الوقت المنقضي\n",
    "            if elapsed_time >= sentence_formation_time_limit:  # التحقق من تجاوز الوقت المحدد\n",
    "                logging.info(\"Formed Sentence: {}\".format(formed_sentence))\n",
    "                # قم بإجراء الإجراء المناسب عند تجميع الجملة\n",
    "                # ...\n",
    "                # إعادة تعيين المتغيرات للجملة التالية\n",
    "                formed_sentence = \"\"\n",
    "                start_time = time.time()\n",
    "        texts_to_speak.append(expected_text)\n",
    "\n",
    "    # Display the modified frame\n",
    "    cv2.imshow(\"Object Detection\", frame_with_text)\n",
    "\n",
    "def process_frames():\n",
    "    ret, frame = cap.read()\n",
    "    if frame.shape[:2] != (800, 600):\n",
    "        frame = cv2.resize(frame, (800, 600))\n",
    "\n",
    "    # Perform object detection and modification on the frame\n",
    "    detect_objects(frame)\n",
    "\n",
    "    # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "while True:\n",
    "    if not process_frames():\n",
    "        break\n",
    "\n",
    "# Release the video capture and close the window\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef2661c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import concurrent.futures\n",
    "import arabic_reshaper\n",
    "import cv2\n",
    "from bidi.algorithm import get_display\n",
    "from ultralytics import YOLO\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from gtts import gTTS\n",
    "import os\n",
    "\n",
    "yolo_model = YOLO(\"/Users/mernaziad/Desktop/final_train/runs/detect/train/weights/best.pt\")\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "font_face = cv2.FONT_HERSHEY_SIMPLEX\n",
    "font_color = (255, 255, 255)\n",
    "thickness = 2\n",
    "font_path = \"/Users/mernaziad/PycharmProjects/GraduationProject/arabic_font.ttf\"\n",
    "font_size = 32  # Adjust the font size as needed\n",
    "# Set the font properties\n",
    "font_scale = 1\n",
    "font_thickness = 2\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "translation_dict = {\n",
    "    '0': '0',\n",
    "    '1': '1',\n",
    "    '2': '2',\n",
    "    '3': '3',\n",
    "    '4': '4',\n",
    "    '5': '5',\n",
    "    '6': '6',\n",
    "    '7': '7',\n",
    "    '8': '8',\n",
    "    '9': '9',\n",
    "    'ALIF': 'أ',\n",
    "    'AYN': 'ع',\n",
    "    'Atman lak 7aya sa3eeda': 'أتمنى لك حياة سعيدة',\n",
    "    'BAA': 'ب',\n",
    "    'DAD': 'ض',\n",
    "    'DELL': 'د',\n",
    "    'DHAA': 'ظ',\n",
    "    'DHELL': 'ذ',\n",
    "    'FAA': 'ف',\n",
    "    'GHAYN': 'غ',\n",
    "    'HA': 'هـ',\n",
    "    'HAA': 'ح',\n",
    "    'JEEM': 'ج',\n",
    "    'KAAF': 'ك',\n",
    "    'KHAA': 'خ',\n",
    "    'LAAM': 'ل',\n",
    "    'MEEM': 'م',\n",
    "    'QAAF': 'ق',\n",
    "    'RAA': 'ر',\n",
    "    'SAD': 'ص',\n",
    "    'SEEN': 'س',\n",
    "    'SHEEN': 'ش',\n",
    "    'TA': 'ت',\n",
    "    'TAA': 'ط',\n",
    "    'THA': 'ث',\n",
    "    'WAW': 'و',\n",
    "    'YA': 'ي',\n",
    "    'ZAY': 'ز',\n",
    "    'bad': 'سيء',\n",
    "    'del': 'حذف',\n",
    "    'eqtibas': 'اقتباس',\n",
    "    'good': 'جيد',\n",
    "    'law sama7t': 'لو سمحت',\n",
    "    'merhaba': 'مرحبا',\n",
    "    'nothing': 'لا شيء',\n",
    "    'o7ebok': 'أحبك',\n",
    "    'oraqebak': 'أراقبك',\n",
    "    'space': 'مسافة',\n",
    "    'you': 'أنت',\n",
    "}\n",
    "\n",
    "\n",
    "def translate_to_arabic(text):\n",
    "    if text in translation_dict:\n",
    "        return translation_dict[text]\n",
    "    else:\n",
    "        return text  # إذا لم تكن الكلمة موجودة في القاموس، استخدم النص الأصلي\n",
    "\n",
    "\n",
    "def convert_text_to_image(text, background_color=(0, 0, 0, 0)):\n",
    "    # Load the specified font\n",
    "    font = ImageFont.truetype(font_path, font_size)\n",
    "\n",
    "    # Create a new image with a transparent background\n",
    "    image = Image.new('RGBA', (1, 1), background_color)\n",
    "\n",
    "    # Create a draw object\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    # Calculate the text size\n",
    "    text_width, text_height = draw.textsize(text, font=font)\n",
    "\n",
    "    # Add some padding to the text size\n",
    "    padding = 10\n",
    "    image_width = text_width + padding\n",
    "    image_height = text_height + padding\n",
    "\n",
    "    # Create a new image with the adjusted dimensions and background color\n",
    "    image = Image.new('RGBA', (image_width, image_height), background_color)\n",
    "\n",
    "    # Create a new draw object with the adjusted image\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    # Calculate the position to place the text at the bottom of the image\n",
    "    text_x = (image.width - text_width) // 2\n",
    "    text_y = image.height - text_height - padding\n",
    "\n",
    "    # Draw the text on the image\n",
    "    draw.text((text_x, text_y), text, font=font, fill=font_color)\n",
    "\n",
    "    # Convert the PIL image to RGB mode\n",
    "    image = image.convert(\"RGB\")\n",
    "\n",
    "    # Convert the PIL image to a NumPy array\n",
    "    image_array = np.array(image)\n",
    "\n",
    "    return image_array\n",
    "\n",
    "\n",
    "def get_arabic_text(text):\n",
    "    reshaped_text = arabic_reshaper.reshape(text)\n",
    "    bidi_text = get_display(reshaped_text)\n",
    "    return bidi_text\n",
    "\n",
    "\n",
    "def overlay_text_on_frame(frame, text_image):\n",
    "    padding = 10\n",
    "    y = frame.shape[0] - text_image.shape[0] - padding\n",
    "    x = (frame.shape[1] - text_image.shape[1]) // 2\n",
    "    frame[y:y + text_image.shape[0], x:x + text_image.shape[1]] = text_image\n",
    "\n",
    "    return frame\n",
    "\n",
    "\n",
    "def detect_objects(frame):\n",
    "    results = yolo_model.predict(frame)\n",
    "    result = results[0]\n",
    "    frame_with_text = frame\n",
    "    texts_to_speak = []\n",
    "    for box in results[0].boxes:\n",
    "        cords = box.xyxy[0].tolist()\n",
    "        cords = [round(x) for x in cords]\n",
    "        class_id = result.names[box.cls[0].item()]\n",
    "        translated_text = translate_to_arabic(class_id)\n",
    "        expected_text = get_arabic_text(translated_text)\n",
    "\n",
    "        conf = round(box.conf[0].item(), 2)\n",
    "        logging.info(\"Object type:{} {}\".format(expected_text, class_id))\n",
    "        logging.info(\"Coordinates: {}\".format(cords))\n",
    "        logging.info(\"Probability: {}\".format(conf))\n",
    "\n",
    "        if conf < 0.5:\n",
    "            return\n",
    "\n",
    "        text_image = convert_text_to_image(expected_text)\n",
    "        frame_with_text = overlay_text_on_frame(frame, text_image)\n",
    "\n",
    "        # Convert the Arabic text to speech\n",
    "        tts = gTTS(text=translated_text, lang='ar')\n",
    "        audio_file = \"/Users/mernaziad/Desktop/text_to_speech.mp3\"\n",
    "        tts.save(audio_file)\n",
    "\n",
    "        # Play the Arabic text as speech\n",
    "        os.system('mpg123 ' + audio_file)\n",
    "        os.remove(audio_file)\n",
    "\n",
    "        texts_to_speak.append(translated_text)\n",
    "\n",
    "    # Display the modified frame\n",
    "    cv2.imshow(\"Object Detection\", frame_with_text)\n",
    "\n",
    "\n",
    "def process_frames():\n",
    "    ret, frame = cap.read()\n",
    "    if frame.shape[:2] != (800, 600):\n",
    "        frame = cv2.resize(frame, (800, 600))\n",
    "    # Perform object detection and modification on the frame\n",
    "    detect_objects(frame)\n",
    "    # Break the loop if 'q' is pressed\n",
    "\n",
    "\n",
    "while True:\n",
    "    process_frames()\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "# executor = concurrent.futures.ThreadPoolExecutor(max_workers=1)\n",
    "# # Submit the process_frames function to the executor\n",
    "# executor.submit(process_frames)\n",
    "# # Wait for the 'q' key to be pressed\n",
    "# while cv2.waitKey(1) & 0xFF != ord('q'):\n",
    "#     pass\n",
    "\n",
    "# # Shutdown the executor\n",
    "# executor.shutdown()\n",
    "# Release the video capture and close the window\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a0b257",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import time\n",
    "import arabic_reshaper\n",
    "import cv2\n",
    "from bidi.algorithm import get_display\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "yolo_model = YOLO(\"/Users/mernaziad/Desktop/final_train/runs/detect/train/weights/best.pt\")  # Replace with the path to your YOLO model weights\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Define the font properties\n",
    "font_face = cv2.FONT_HERSHEY_SIMPLEX\n",
    "font_color = (255, 255, 255)\n",
    "thickness = 2\n",
    "font_path = \"/Users/mernaziad/PycharmProjects/GraduationProject/arabic_font.ttf\"  # Replace with the path to your Arabic font file\n",
    "font_size = 32\n",
    "font_scale = 1\n",
    "font_thickness = 2\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Translation dictionary\n",
    "translation_dict = {\n",
    "    '0':'0',\n",
    "    '1':'1', \n",
    "    '2':'2', \n",
    "    '3':'3', \n",
    "    '4':'4', \n",
    "    '5':'5', \n",
    "    '6':'6', \n",
    "    '7':'7', \n",
    "    '8':'8', \n",
    "    '9':'9', \n",
    "    'ALIF':'أ', \n",
    "    'AYN':'ع', \n",
    "    'Atman lak 7aya sa3eeda' :'أتمنى لك حياة سعيدة', \n",
    "    'BAA':'ب', \n",
    "    'DAD':'ض', \n",
    "    'DELL':'د', \n",
    "    'DHAA':'ظ', \n",
    "    'DHELL':'ذ', \n",
    "    'FAA':'ف', \n",
    "    'GHAYN':'غ', \n",
    "    'HA':'هـ', \n",
    "    'HAA':'ح', \n",
    "    'JEEM':'ج', \n",
    "    'KAAF':'ك', \n",
    "    'KHAA':'خ', \n",
    "    'LAAM':'ل', \n",
    "    'MEEM':'م', \n",
    "    'QAAF':'ق', \n",
    "    'RAA':'ر', \n",
    "    'SAD':'ص', \n",
    "    'SEEN':'س', \n",
    "    'SHEEN':'ش', \n",
    "    'TA':'ت', \n",
    "    'TAA':'ط', \n",
    "    'THA':'ث', \n",
    "    'WAW':'و', \n",
    "    'YA':'ي', \n",
    "    'ZAY':'ز', \n",
    "    'bad':'سيء', \n",
    "    'del':'حذف', \n",
    "    'eqtibas':'اقتباس', \n",
    "    'good':'جيد', \n",
    "    'law sama7t':'لو سمحت', \n",
    "    'merhaba':'مرحبا', \n",
    "    'nothing':'لا شيء', \n",
    "    'o7ebok':'أحبك', \n",
    "    'oraqebak':'أراقبك', \n",
    "    'space':'مسافة', \n",
    "    'you':'أنت', \n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "def translate_to_arabic(text):\n",
    "    if text in translation_dict:\n",
    "        return translation_dict[text]\n",
    "    else:\n",
    "        return text  # If the word is not in the translation dictionary, use the original text\n",
    "\n",
    "def convert_text_to_image(text, background_color=(0, 0, 0, 0)):\n",
    "    # Load the specified font\n",
    "    font = ImageFont.truetype(font_path, font_size)\n",
    "\n",
    "    # Create a new image with a transparent background\n",
    "    image = Image.new('RGBA', (1, 1), background_color)\n",
    "\n",
    "    # Create a draw object\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    # Calculate the text size\n",
    "    text_width, text_height = draw.textsize(text, font=font)\n",
    "\n",
    "    # Add some padding to the text size\n",
    "    padding = 10\n",
    "    image_width = text_width + padding\n",
    "    image_height = text_height + padding\n",
    "\n",
    "    # Create a new image with the adjusted dimensions and background color\n",
    "    image = Image.new('RGBA', (image_width, image_height), background_color)\n",
    "\n",
    "    # Create a new draw object with the adjusted image\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    # Calculate the position to place the text at the bottom of the image\n",
    "    text_x = (image.width - text_width) // 2\n",
    "    text_y = image.height - text_height - padding\n",
    "\n",
    "    # Draw the text on the image\n",
    "    draw.text((text_x, text_y), text, font=font, fill=font_color)\n",
    "\n",
    "    # Convert the PIL image to RGB mode\n",
    "    image = image.convert(\"RGB\")\n",
    "\n",
    "    # Convert the PIL image to a NumPy array\n",
    "    image_array = np.array(image)\n",
    "\n",
    "    return image_array\n",
    "\n",
    "def get_arabic_text(text):\n",
    "    reshaped_text = arabic_reshaper.reshape(text)\n",
    "    bidi_text = get_display(reshaped_text)\n",
    "    return bidi_text\n",
    "\n",
    "def overlay_text_on_frame(frame, words):\n",
    "    padding = 10\n",
    "    text_widths = []\n",
    "    text_heights = []\n",
    "\n",
    "    # Calculate the dimensions of each text image\n",
    "    for word in words:\n",
    "        text_image = convert_text_to_image(word)\n",
    "        text_width, text_height = text_image.shape[1], text_image.shape[0]\n",
    "        text_widths.append(text_width)\n",
    "        text_heights.append(text_height)\n",
    "\n",
    "    if len(text_widths) == 0 or len(text_heights) == 0:\n",
    "        return frame\n",
    "\n",
    "    y = frame.shape[0] - sum(text_heights) - (padding * len(words))\n",
    "    x = (frame.shape[1] - max(text_widths)) // 2\n",
    "\n",
    "    for word, width, height in zip(words, text_widths, text_heights):\n",
    "        text_image = convert_text_to_image(word)\n",
    "        frame[y:y + height, x:x + width] = text_image\n",
    "        y += height + padding\n",
    "\n",
    "    return frame\n",
    "word_combinations = {}\n",
    "formed_sentence = \"\"\n",
    "\n",
    "def detect_objects(frame):\n",
    "    global formed_sentence, start_time, word_combinations\n",
    "    \n",
    "    results = yolo_model.predict(frame)\n",
    "    result = results[0]\n",
    "    frame_with_text = frame\n",
    "    texts_to_speak = []\n",
    "\n",
    "    for box in results[0].boxes:\n",
    "        cords = box.xyxy[0].tolist()\n",
    "        cords = [round(x) for x in cords]\n",
    "        class_id = result.names[box.cls[0].item()]\n",
    "        translated_text = translate_to_arabic(class_id)\n",
    "        expected_text = get_arabic_text(translated_text)\n",
    "\n",
    "        conf = round(box.conf[0].item(), 2)\n",
    "        logging.info(\"Object type:{} {}\".format(expected_text, class_id))\n",
    "        logging.info(\"Coordinates: {}\".format(cords))\n",
    "        logging.info(\"Probability: {}\".format(conf))\n",
    "\n",
    "        if conf < 0.5:\n",
    "            continue\n",
    "\n",
    "        text_image = convert_text_to_image(expected_text)\n",
    "#         frame_with_text = overlay_text_on_frame(frame, text_image)\n",
    "        frame_with_text = overlay_text_on_frame(frame_with_text, list(word_combinations.keys()))\n",
    "\n",
    "\n",
    "        if translated_text != \"\":\n",
    "            formed_sentence += translated_text\n",
    "            if len(formed_sentence) >= 2:  # Check if there are at least two characters in the formed sentence\n",
    "                word_combinations[formed_sentence] = True\n",
    "\n",
    "    # Display the modified frame\n",
    "    cv2.imshow(\"Object Detection\", frame_with_text)\n",
    "\n",
    "def process_frames():\n",
    "    ret, frame = cap.read()\n",
    "    if frame.shape[:2] != (800, 600):\n",
    "        frame = cv2.resize(frame, (800, 600))\n",
    "    \n",
    "    # Perform object detection and modification on the frame\n",
    "    detect_objects(frame)\n",
    "    frame_with_text = overlay_text_on_frame(frame, list(word_combinations.keys()))\n",
    "\n",
    "#     print(\"Word Combinations:\")\n",
    "#     for word in word_combinations:\n",
    "#         print(word)\n",
    "    combined_words = ' '.join(word_combinations.keys())\n",
    "    print(\"Combined Words:\", combined_words)\n",
    "    # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "while True:\n",
    "    if not process_frames():\n",
    "        break\n",
    "\n",
    "# Release the video capture and close the window\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "# Combine the words from the dictionary\n",
    "combined_words = ' '.join(word_combinations.keys())\n",
    "print(\"Combined Words:\", combined_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62c0560",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8616e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import time\n",
    "import arabic_reshaper\n",
    "import cv2\n",
    "from bidi.algorithm import get_display\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "yolo_model = YOLO(\"/Users/mernaziad/Desktop/final_train/runs/detect/train/weights/best.pt\")  # Replace with the path to your YOLO model weights\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Define the font properties\n",
    "font_face = cv2.FONT_HERSHEY_SIMPLEX\n",
    "font_color = (255, 255, 255)\n",
    "thickness = 2\n",
    "font_path = \"/Users/mernaziad/PycharmProjects/GraduationProject/arabic_font.ttf\"  # Replace with the path to your Arabic font file\n",
    "font_size = 32\n",
    "font_scale = 1\n",
    "font_thickness = 2\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Translation dictionary\n",
    "translation_dict = {\n",
    "    '0':'0',\n",
    "    '1':'1', \n",
    "    '2':'2', \n",
    "    '3':'3', \n",
    "    '4':'4', \n",
    "    '5':'5', \n",
    "    '6':'6', \n",
    "    '7':'7', \n",
    "    '8':'8', \n",
    "    '9':'9', \n",
    "    'ALIF':'أ', \n",
    "    'AYN':'ع', \n",
    "    'Atman lak 7aya sa3eeda' :'أتمنى لك حياة سعيدة', \n",
    "    'BAA':'ب', \n",
    "    'DAD':'ض', \n",
    "    'DELL':'د', \n",
    "    'DHAA':'ظ', \n",
    "    'DHELL':'ذ', \n",
    "    'FAA':'ف', \n",
    "    'GHAYN':'غ', \n",
    "    'HA':'هـ', \n",
    "    'HAA':'ح', \n",
    "    'JEEM':'ج', \n",
    "    'KAAF':'ك', \n",
    "    'KHAA':'خ', \n",
    "    'LAAM':'ل', \n",
    "    'MEEM':'م', \n",
    "    'QAAF':'ق', \n",
    "    'RAA':'ر', \n",
    "    'SAD':'ص', \n",
    "    'SEEN':'س', \n",
    "    'SHEEN':'ش', \n",
    "    'TA':'ت', \n",
    "    'TAA':'ط', \n",
    "    'THA':'ث', \n",
    "    'WAW':'و', \n",
    "    'YA':'ي', \n",
    "    'ZAY':'ز', \n",
    "    'bad':'سيء', \n",
    "    'del':'حذف', \n",
    "    'eqtibas':'اقتباس', \n",
    "    'good':'جيد', \n",
    "    'law sama7t':'لو سمحت', \n",
    "    'merhaba':'مرحبا', \n",
    "    'nothing':'لا شيء', \n",
    "    'o7ebok':'أحبك', \n",
    "    'oraqebak':'أراقبك', \n",
    "    'space':'مسافة', \n",
    "    'you':'أنت', \n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "def translate_to_arabic(text):\n",
    "    if text in translation_dict:\n",
    "        return translation_dict[text]\n",
    "    else:\n",
    "        return text  # If the word is not in the translation dictionary, use the original text\n",
    "\n",
    "def convert_text_to_image(text, background_color=(0, 0, 0, 0)):\n",
    "    # Load the specified font\n",
    "    font = ImageFont.truetype(font_path, font_size)\n",
    "\n",
    "    # Create a new image with a transparent background\n",
    "    image = Image.new('RGBA', (1, 1), background_color)\n",
    "\n",
    "    # Create a draw object\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    # Calculate the text size\n",
    "    text_width, text_height = draw.textsize(text, font=font)\n",
    "\n",
    "    # Add some padding to the text size\n",
    "    padding = 10\n",
    "    image_width = text_width + padding\n",
    "    image_height = text_height + padding\n",
    "\n",
    "    # Create a new image with the adjusted dimensions and background color\n",
    "    image = Image.new('RGBA', (image_width, image_height), background_color)\n",
    "\n",
    "    # Create a new draw object with the adjusted image\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    # Calculate the position to place the text at the bottom of the image\n",
    "    text_x = (image.width - text_width) // 2\n",
    "    text_y = image.height - text_height - padding\n",
    "\n",
    "    # Draw the text on the image\n",
    "    draw.text((text_x, text_y), text, font=font, fill=font_color)\n",
    "\n",
    "    # Convert the PIL image to RGB mode\n",
    "    image = image.convert(\"RGB\")\n",
    "\n",
    "    # Convert the PIL image to a NumPy array\n",
    "    image_array = np.array(image)\n",
    "\n",
    "    return image_array\n",
    "\n",
    "def get_arabic_text(text):\n",
    "    reshaped_text = arabic_reshaper.reshape(text)\n",
    "    bidi_text = get_display(reshaped_text)\n",
    "    return bidi_text\n",
    "\n",
    "def overlay_text_on_frame(frame, words):\n",
    "    padding = 10\n",
    "    text_widths = []\n",
    "    text_heights = []\n",
    "\n",
    "    # Calculate the dimensions of each text image\n",
    "    for word in words:\n",
    "        text_image = convert_text_to_image(word)\n",
    "        text_width, text_height = text_image.shape[1], text_image.shape[0]\n",
    "        text_widths.append(text_width)\n",
    "        text_heights.append(text_height)\n",
    "\n",
    "    y = frame.shape[0] - sum(text_heights) - (padding * len(words))\n",
    "    \n",
    "    if len(text_widths) > 0:\n",
    "        max_width = max(text_widths)\n",
    "        max_height = max(text_heights)\n",
    "    else:\n",
    "        max_width = 0\n",
    "        max_height = 0\n",
    "    \n",
    "    x = (frame.shape[1] - max_width) // 2\n",
    "\n",
    "    for word, width, height in zip(words, text_widths, text_heights):\n",
    "        text_image = convert_text_to_image(word)\n",
    "        frame[y:y + height, x:x + width] = text_image\n",
    "        y += height + padding\n",
    "\n",
    "    # Add the combined words to the list of words\n",
    "    combined_words = ' '.join(words)\n",
    "    combined_words_image = convert_text_to_image(combined_words)\n",
    "    combined_words_width, combined_words_height = combined_words_image.shape[1], combined_words_image.shape[0]\n",
    "\n",
    "    # Calculate the position to place the combined words\n",
    "    combined_words_x = (frame.shape[1] - combined_words_width) // 2\n",
    "    combined_words_y = y + max_height + padding\n",
    "\n",
    "    # Overlay the combined words on the frame\n",
    "    frame[combined_words_y:combined_words_y + combined_words_height, combined_words_x:combined_words_x + combined_words_width] = combined_words_image\n",
    "\n",
    "    return frame\n",
    "word_combinations = {}\n",
    "\n",
    "def detect_objects(frame):\n",
    "    global formed_sentence, start_time, word_combinations\n",
    "    \n",
    "    results = yolo_model.predict(frame)\n",
    "    result = results[0]\n",
    "    frame_with_text = frame\n",
    "    texts_to_speak = []\n",
    "\n",
    "    for box in results[0].boxes:\n",
    "        cords = box.xyxy[0].tolist()\n",
    "        cords = [round(x) for x in cords]\n",
    "        class_id = result.names[box.cls[0].item()]\n",
    "        translated_text = translate_to_arabic(class_id)\n",
    "        expected_text = get_arabic_text(translated_text)\n",
    "\n",
    "        conf = round(box.conf[0].item(), 2)\n",
    "        logging.info(\"Object type:{} {}\".format(expected_text, class_id))\n",
    "        logging.info(\"Coordinates: {}\".format(cords))\n",
    "        logging.info(\"Probability: {}\".format(conf))\n",
    "\n",
    "        if conf < 0.5:\n",
    "            continue\n",
    "\n",
    "        text_image = convert_text_to_image(expected_text)\n",
    "        frame_with_text = overlay_text_on_frame(frame, text_image)\n",
    "\n",
    "        if translated_text != \"\":\n",
    "            formed_sentence += translated_text\n",
    "            if len(formed_sentence) >= 2:  # Check if there are at least two characters in the formed sentence\n",
    "                word_combinations[formed_sentence] = True\n",
    "\n",
    "    # Display the modified frame\n",
    "    cv2.imshow(\"Object Detection\", frame_with_text)\n",
    "\n",
    "def process_frames():\n",
    "    ret, frame = cap.read()\n",
    "    if frame.shape[:2] != (800, 600):\n",
    "        frame = cv2.resize(frame, (800, 600))\n",
    "    \n",
    "    # Perform object detection and modification on the frame\n",
    "    detect_objects(frame)\n",
    "    frame_with_text = overlay_text_on_frame(frame, list(word_combinations.keys()))\n",
    "\n",
    "#     print(\"Word Combinations:\")\n",
    "#     for word in word_combinations:\n",
    "#         print(word)\n",
    "    combined_words = ' '.join(word_combinations.keys())\n",
    "    print(\"Combined Words:\", combined_words)\n",
    "    # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "while True:\n",
    "    if not process_frames():\n",
    "        break\n",
    "\n",
    "# Release the video capture and close the window\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "# Combine the words from the dictionary\n",
    "combined_words = ' '.join(word_combinations.keys())\n",
    "print(\"Combined Words:\", combined_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1994cf66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import time\n",
    "import arabic_reshaper\n",
    "import cv2\n",
    "from bidi.algorithm import get_display\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "yolo_model = YOLO(\"/Users/mernaziad/Desktop/final_train/runs/detect/train/weights/best.pt\")  # Replace with the path to your YOLO model weights\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Define the font properties\n",
    "font_face = cv2.FONT_HERSHEY_SIMPLEX\n",
    "font_color = (255, 255, 255)\n",
    "thickness = 2\n",
    "font_path = \"/Users/mernaziad/PycharmProjects/GraduationProject/arabic_font.ttf\"  # Replace with the path to your Arabic font file\n",
    "font_size = 32\n",
    "font_scale = 1\n",
    "font_thickness = 2\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Translation dictionary\n",
    "translation_dict = {\n",
    "    '0':'0',\n",
    "    '1':'1', \n",
    "    '2':'2', \n",
    "    '3':'3', \n",
    "    '4':'4', \n",
    "    '5':'5', \n",
    "    '6':'6', \n",
    "    '7':'7', \n",
    "    '8':'8', \n",
    "    '9':'9', \n",
    "    'ALIF':'أ', \n",
    "    'AYN':'ع', \n",
    "    'Atman lak 7aya sa3eeda' :'أتمنى لك حياة سعيدة', \n",
    "    'BAA':'ب', \n",
    "    'DAD':'ض', \n",
    "    'DELL':'د', \n",
    "    'DHAA':'ظ', \n",
    "    'DHELL':'ذ', \n",
    "    'FAA':'ف', \n",
    "    'GHAYN':'غ', \n",
    "    'HA':'هـ', \n",
    "    'HAA':'ح', \n",
    "    'JEEM':'ج', \n",
    "    'KAAF':'ك', \n",
    "    'KHAA':'خ', \n",
    "    'LAAM':'ل', \n",
    "    'MEEM':'م', \n",
    "    'QAAF':'ق', \n",
    "    'RAA':'ر', \n",
    "    'SAD':'ص', \n",
    "    'SEEN':'س', \n",
    "    'SHEEN':'ش', \n",
    "    'TA':'ت', \n",
    "    'TAA':'ط', \n",
    "    'THA':'ث', \n",
    "    'WAW':'و', \n",
    "    'YA':'ي', \n",
    "    'ZAY':'ز', \n",
    "    'bad':'سيء', \n",
    "    'del':'حذف', \n",
    "    'eqtibas':'اقتباس', \n",
    "    'good':'جيد', \n",
    "    'law sama7t':'لو سمحت', \n",
    "    'merhaba':'مرحبا', \n",
    "    'nothing':'لا شيء', \n",
    "    'o7ebok':'أحبك', \n",
    "    'oraqebak':'أراقبك', \n",
    "    'space':'مسافة', \n",
    "    'you':'أنت', \n",
    "}\n",
    "\n",
    "# Word dictionary\n",
    "word_dictionary = {\n",
    "    'أب': True,\n",
    "    'أبي': True,\n",
    "}\n",
    "\n",
    "def translate_to_arabic(text):\n",
    "    if text in translation_dict:\n",
    "        return translation_dict[text]\n",
    "    else:\n",
    "        return text  # If the word is not in the translation dictionary, use the original text\n",
    "\n",
    "def convert_text_to_image(text, background_color=(0, 0, 0, 0)):\n",
    "    # Load the specified font\n",
    "    font = ImageFont.truetype(font_path, font_size)\n",
    "\n",
    "    # Create a new image with a transparent background\n",
    "    image = Image.new('RGBA', (1, 1), background_color)\n",
    "\n",
    "    # Create a draw object\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    # Calculate the text size\n",
    "    text_width, text_height = draw.textsize(text, font=font)\n",
    "\n",
    "    # Add some padding to the text size\n",
    "    padding = 10\n",
    "    image_width = text_width + padding\n",
    "    image_height = text_height + padding\n",
    "\n",
    "    # Create a new image with the adjusted dimensions and background color\n",
    "    image = Image.new('RGBA', (image_width, image_height), background_color)\n",
    "\n",
    "    # Create a new draw object with the adjusted image\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    # Calculate the position to place the text at the bottom of the image\n",
    "    text_x = (image.width - text_width) // 2\n",
    "    text_y = image.height - text_height - padding\n",
    "\n",
    "    # Draw the text on the image\n",
    "    draw.text((text_x, text_y), text, font=font, fill=font_color)\n",
    "\n",
    "    # Convert the PIL image to RGB mode\n",
    "    image = image.convert(\"RGB\")\n",
    "\n",
    "    # Convert the PIL image to a NumPy array\n",
    "    image_array = np.array(image)\n",
    "\n",
    "    return image_array\n",
    "\n",
    "def get_arabic_text(text):\n",
    "    reshaped_text = arabic_reshaper.reshape(text)\n",
    "    bidi_text = get_display(reshaped_text)\n",
    "    return bidi_text\n",
    "\n",
    "def overlay_text_on_frame(frame, words):\n",
    "    padding = 10\n",
    "    text_widths = []\n",
    "    text_heights = []\n",
    "\n",
    "    # Calculate the dimensions of each text image\n",
    "    for word in words:\n",
    "        text_image = convert_text_to_image(word)\n",
    "        text_width, text_height = text_image.shape[1], text_image.shape[0]\n",
    "        text_widths.append(text_width)\n",
    "        text_heights.append(text_height)\n",
    "\n",
    "    y = frame.shape[0] - sum(text_heights) - (padding * len(words))\n",
    "    \n",
    "    if len(text_widths) > 0:\n",
    "        max_width = max(text_widths)\n",
    "        max_height = max(text_heights)\n",
    "    else:\n",
    "        max_width = 0\n",
    "        max_height = 0\n",
    "    \n",
    "    x = (frame.shape[1] - max_width) // 2\n",
    "\n",
    "    for word, width, height in zip(words, text_widths, text_heights):\n",
    "        text_image = convert_text_to_image(word)\n",
    "        frame[y:y + height, x:x + width] = text_image\n",
    "        y += height + padding\n",
    "\n",
    "        # Check if the formed sentence is in the word dictionary\n",
    "        if formed_sentence in word_dictionary:\n",
    "            word_combinations[formed_sentence] = True\n",
    "\n",
    "    # Add the combined words to the list of words\n",
    "    combined_words = ' '.join(words)\n",
    "    combined_words_image = convert_text_to_image(combined_words)\n",
    "    combined_words_width, combined_words_height = combined_words_image.shape[1], combined_words_image.shape[0]\n",
    "\n",
    "    # Calculate the position to place the combined words\n",
    "    combined_words_x = (frame.shape[1] - combined_words_width) // 2\n",
    "    combined_words_y = y + max_height + padding\n",
    "\n",
    "    # Overlay the combined words on the frame\n",
    "    frame[combined_words_y:combined_words_y + combined_words_height, combined_words_x:combined_words_x + combined_words_width] = combined_words_image\n",
    "\n",
    "    return frame\n",
    "\n",
    "word_combinations = {}\n",
    "\n",
    "def detect_objects(frame):\n",
    "    global formed_sentence, start_time, word_combinations\n",
    "    \n",
    "    results = yolo_model.predict(frame)\n",
    "    result = results[0]\n",
    "    frame_with_text = frame\n",
    "    texts_to_speak = []\n",
    "\n",
    "    for box in results[0].boxes:\n",
    "        cords = box.xyxy[0].tolist()\n",
    "        cords = [round(x) for x in cords]\n",
    "        class_id = result.names[box.cls[0].item()]\n",
    "        translated_text = translate_to_arabic(class_id)\n",
    "        expected_text = get_arabic_text(translated_text)\n",
    "\n",
    "        conf = round(box.conf[0].item(), 2)\n",
    "        logging.info(\"Object type:{} {}\".format(expected_text, class_id))\n",
    "        logging.info(\"Coordinates: {}\".format(cords))\n",
    "        logging.info(\"Probability: {}\".format(conf))\n",
    "\n",
    "        if conf < 0.5:\n",
    "            continue\n",
    "\n",
    "        text_image = convert_text_to_image(expected_text)\n",
    "        frame_with_text = overlay_text_on_frame(frame, [expected_text])\n",
    "\n",
    "        if translated_text != \"\":\n",
    "            formed_sentence += translated_text\n",
    "\n",
    "    # Display the modified frame\n",
    "    cv2.imshow(\"Object Detection\", frame_with_text)\n",
    "\n",
    "def process_frames():\n",
    "    ret, frame = cap.read()\n",
    "    if frame.shape[:2] != (800, 600):\n",
    "        frame = cv2.resize(frame, (800, 600))\n",
    "    \n",
    "    # Perform object detection and modification on the frame\n",
    "    detect_objects(frame)\n",
    "    frame_with_text = overlay_text_on_frame(frame, list(word_combinations.keys()))\n",
    "\n",
    "    # Print the word combinations\n",
    "    combined_words = ' '.join(word_combinations.keys())\n",
    "    print(\"Combined Words:\", combined_words)\n",
    "    \n",
    "    # Process frames continuously\n",
    "    while True:\n",
    "        # Read the frame from the camera\n",
    "        ret, frame = cap.read()\n",
    "        if frame.shape[:2] != (800, 600):\n",
    "            frame = cv2.resize(frame, (800, 600))\n",
    "\n",
    "        # Perform object detection and modification on the frame\n",
    "        detect_objects(frame)\n",
    "        frame_with_text = overlay_text_on_frame(frame, list(word_combinations.keys()))\n",
    "\n",
    "        # Print the word combinations\n",
    "        combined_words = ' '.join(word_combinations.keys())\n",
    "        print(\"Combined Words:\", combined_words)\n",
    "\n",
    "        # Display the modified frame\n",
    "        cv2.imshow(\"Object Detection\", frame_with_text)\n",
    "\n",
    "        # Break the loop if 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release the capture and close windows\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    formed_sentence = \"\"\n",
    "    start_time = time.time()\n",
    "    process_frames()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725e051c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import time\n",
    "import arabic_reshaper\n",
    "import cv2\n",
    "from bidi.algorithm import get_display\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "# Replace with the path to your YOLO model weights\n",
    "yolo_model = YOLO(\"/Users/mernaziad/Desktop/final_train/runs/detect/train/weights/best.pt\")\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Define the font properties\n",
    "font_face = cv2.FONT_HERSHEY_SIMPLEX\n",
    "font_color = (255, 255, 255)\n",
    "thickness = 2\n",
    "font_path = \"/Users/mernaziad/PycharmProjects/GraduationProject/arabic_font.ttf\"  # Replace with the path to your Arabic font file\n",
    "font_size = 32\n",
    "font_scale = 1\n",
    "font_thickness = 2\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Translation dictionary\n",
    "translation_dict = {\n",
    "    '0': '0',\n",
    "    '1': '1',\n",
    "    '2': '2',\n",
    "    '3': '3',\n",
    "    '4': '4',\n",
    "    '5': '5',\n",
    "    '6': '6',\n",
    "    '7': '7',\n",
    "    '8': '8',\n",
    "    '9': '9',\n",
    "    'ALIF': 'أ',\n",
    "    'AYN': 'ع',\n",
    "    'Atman lak 7aya sa3eeda': 'أتمنى لك حياة سعيدة',\n",
    "    'BAA': 'ب',\n",
    "    'DAD': 'ض',\n",
    "    'DELL': 'د',\n",
    "    'DHAA': 'ظ',\n",
    "    'DHELL': 'ذ',\n",
    "    'FAA': 'ف',\n",
    "    'GHAYN': 'غ',\n",
    "    'HA': 'هـ',\n",
    "    'HAA': 'ح',\n",
    "    'JEEM': 'ج',\n",
    "    'KAAF': 'ك',\n",
    "    'KHAA': 'خ',\n",
    "    'LAAM': 'ل',\n",
    "    'MEEM': 'م',\n",
    "    'QAAF': 'ق',\n",
    "    'RAA': 'ر',\n",
    "    'SAD': 'ص',\n",
    "    'SEEN': 'س',\n",
    "    'SHEEN': 'ش',\n",
    "    'TA': 'ت',\n",
    "    'TAA': 'ط',\n",
    "    'THA': 'ث',\n",
    "    'WAW': 'و',\n",
    "    'YA': 'ي',\n",
    "    'ZAY': 'ز',\n",
    "    'bad': 'سيء',\n",
    "    'del': 'حذف',\n",
    "    'eqtibas': 'اقتباس',\n",
    "    'good': 'جيد',\n",
    "    'law sama7t': 'لو سمحت',\n",
    "    'merhaba': 'مرحبا',\n",
    "    'nothing': 'لا شيء',\n",
    "    'o7ebok': 'أحبك',\n",
    "    'oraqebak': 'أراقبك',\n",
    "    'space': 'مسافة',\n",
    "    'you': 'أنت',\n",
    "}\n",
    "\n",
    "# Word dictionary\n",
    "word_dictionary = {\n",
    "    'أب': True,\n",
    "    'أبي': True,\n",
    "}\n",
    "\n",
    "def translate_to_arabic(text):\n",
    "    if text in translation_dict:\n",
    "        return translation_dict[text]\n",
    "    else:\n",
    "        return text  # If the word is not in the translation dictionary, use the original text\n",
    "\n",
    "def convert_text_to_image(text, background_color=(0, 0, 0, 0)):\n",
    "    # Load the specified font\n",
    "    font = ImageFont.truetype(font_path, font_size)\n",
    "\n",
    "    # Create a new image with a transparent background\n",
    "    image = Image.new('RGBA', (1, 1), background_color)\n",
    "\n",
    "    # Create a draw object\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    # Calculate the text size\n",
    "    text_width, text_height = draw.textsize(text, font=font)\n",
    "\n",
    "    # Add some padding to the text size\n",
    "    padding = 10\n",
    "    image_width = text_width + padding\n",
    "    image_height = text_height + padding\n",
    "\n",
    "    # Create a new image with the adjusted dimensions and background color\n",
    "    image = Image.new('RGBA', (image_width, image_height), background_color)\n",
    "\n",
    "    # Create a new draw object with the adjusted image\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    # Calculate the position to place the text at the bottom of the image\n",
    "    text_x = (image.width - text_width) // 2\n",
    "    text_y = image.height - text_height - padding\n",
    "\n",
    "    # Draw the text on the image\n",
    "    draw.text((text_x, text_y), text, font=font, fill=font_color)\n",
    "\n",
    "    # Convert the PIL image to RGB mode\n",
    "    image = image.convert(\"RGB\")\n",
    "\n",
    "    # Convert the PIL image to a NumPy array\n",
    "    image_array = np.array(image)\n",
    "\n",
    "    return image_array\n",
    "\n",
    "def get_arabic_text(text):\n",
    "    reshaped_text = arabic_reshaper.reshape(text)\n",
    "    bidi_text = get_display(reshaped_text)\n",
    "    return bidi_text\n",
    "\n",
    "def overlay_text_on_frame(frame, words):\n",
    "    padding = 10\n",
    "    text_widths = []\n",
    "    text_heights = []\n",
    "\n",
    "    # Calculate the dimensions of each text image\n",
    "    for word in words:\n",
    "        text_image = convert_text_to_image(word)\n",
    "        text_width, text_height = text_image.shape[1], text_image.shape[0]\n",
    "        text_widths.append(text_width)\n",
    "        text_heights.append(text_height)\n",
    "\n",
    "    y = frame.shape[0] - sum(text_heights) - (padding * len(words))\n",
    "\n",
    "    if len(text_widths) > 0:\n",
    "        max_width = max(text_widths)\n",
    "        max_height = max(text_heights)\n",
    "    else:\n",
    "        max_width = 0\n",
    "        max_height = 0\n",
    "\n",
    "    x = (frame.shape[1] - max_width) // 2\n",
    "\n",
    "    for word, width, height in zip(words, text_widths, text_heights):\n",
    "        text_image = convert_text_to_image(word)\n",
    "        frame[y:y + height, x:x + width] = text_image\n",
    "        y += height + padding\n",
    "\n",
    "        # Check if the formed sentence is in the word dictionary\n",
    "        if formed_sentence in word_dictionary:\n",
    "            word_combinations[formed_sentence] = True\n",
    "\n",
    "    # Add the combined words to the list of words\n",
    "    combined_words = ' '.join(words)\n",
    "    combined_words_image = convert_text_to_image(combined_words)\n",
    "    combined_words_width, combined_words_height = combined_words_image.shape[1], combined_words_image.shape[0]\n",
    "\n",
    "    # Calculate the position to place the combined words\n",
    "    combined_words_x = (frame.shape[1] - combined_words_width) // 2\n",
    "    combined_words_y = y + max_height + padding\n",
    "\n",
    "    # Overlay the combined words on the frame\n",
    "    frame[combined_words_y:combined_words_y + combined_words_height, combined_words_x:combined_words_x + combined_words_width] = combined_words_image\n",
    "\n",
    "    return frame\n",
    "\n",
    "word_combinations = {}\n",
    "\n",
    "def detect_objects(frame):\n",
    "    results = yolo_model(frame)\n",
    "\n",
    "    # Extract the bounding box coordinates and class labels\n",
    "    boxes = results.xyxy[0][:, :4].tolist()\n",
    "    labels = results.xyxy[0][:, -1].tolist()\n",
    "\n",
    "    # Filter out non-object classes and get their corresponding labels\n",
    "    object_labels = [translate_to_arabic(str(label)) for label in labels]\n",
    "\n",
    "    return boxes, object_labels\n",
    "\n",
    "def process_frame(frame):\n",
    "    # Convert the frame from BGR to RGB\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Detect objects in the frame\n",
    "    boxes, object_labels = detect_objects(rgb_frame)\n",
    "\n",
    "    # Create a list to store the detected objects\n",
    "    detected_objects = []\n",
    "\n",
    "    for label in object_labels:\n",
    "        # Add the label to the detected objects list\n",
    "        detected_objects.append(label)\n",
    "\n",
    "    # Combine the detected words into a sentence\n",
    "    formed_sentence = ' '.join(detected_objects)\n",
    "\n",
    "    # Overlay the formed sentence on the frame\n",
    "    frame_with_text = overlay_text_on_frame(frame, detected_objects)\n",
    "\n",
    "    return frame_with_text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c9e4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import time\n",
    "import arabic_reshaper\n",
    "import cv2\n",
    "from bidi.algorithm import get_display\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "# Replace with the path to your YOLO model weights\n",
    "yolo_model = YOLO(\"/Users/mernaziad/Desktop/final_train/runs/detect/train/weights/best.pt\")\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Define the font properties\n",
    "font_face = cv2.FONT_HERSHEY_SIMPLEX\n",
    "font_color = (255, 255, 255)\n",
    "thickness = 2\n",
    "font_path = \"/Users/mernaziad/PycharmProjects/GraduationProject/arabic_font.ttf\"  # Replace with the path to your Arabic font file\n",
    "font_size = 32\n",
    "font_scale = 1\n",
    "font_thickness = 2\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Translation dictionary\n",
    "translation_dict = {\n",
    "    '0': '0',\n",
    "    '1': '1',\n",
    "    '2': '2',\n",
    "    '3': '3',\n",
    "    '4': '4',\n",
    "    '5': '5',\n",
    "    '6': '6',\n",
    "    '7': '7',\n",
    "    '8': '8',\n",
    "    '9': '9',\n",
    "    'ALIF': 'أ',\n",
    "    'AYN': 'ع',\n",
    "    'Atman lak 7aya sa3eeda': 'أتمنى لك حياة سعيدة',\n",
    "    'BAA': 'ب',\n",
    "    'DAD': 'ض',\n",
    "    'DELL': 'د',\n",
    "    'DHAA': 'ظ',\n",
    "    'DHELL': 'ذ',\n",
    "    'FAA': 'ف',\n",
    "    'GHAYN': 'غ',\n",
    "    'HA': 'هـ',\n",
    "    'HAA': 'ح',\n",
    "    'JEEM': 'ج',\n",
    "    'KAAF': 'ك',\n",
    "    'KHAA': 'خ',\n",
    "    'LAAM': 'ل',\n",
    "    'MEEM': 'م',\n",
    "    'QAAF': 'ق',\n",
    "    'RAA': 'ر',\n",
    "    'SAD': 'ص',\n",
    "    'SEEN': 'س',\n",
    "    'SHEEN': 'ش',\n",
    "    'TA': 'ت',\n",
    "    'TAA': 'ط',\n",
    "    'THA': 'ث',\n",
    "    'WAW': 'و',\n",
    "    'YA': 'ي',\n",
    "    'ZAY': 'ز',\n",
    "    'bad': 'سيء',\n",
    "    'del': 'حذف',\n",
    "    'eqtibas': 'اقتباس',\n",
    "    'good': 'جيد',\n",
    "    'law sama7t': 'لو سمحت',\n",
    "    'merhaba': 'مرحبا',\n",
    "    'nothing': 'لا شيء',\n",
    "    'o7ebok': 'أحبك',\n",
    "    'oraqebak': 'أراقبك',\n",
    "    'space': 'مسافة',\n",
    "    'you': 'أنت',\n",
    "}\n",
    "\n",
    "# Word dictionary\n",
    "word_dictionary = {\n",
    "    'أب': True,\n",
    "    'أبي': True,\n",
    "}\n",
    "\n",
    "def translate_to_arabic(text):\n",
    "    if text in translation_dict:\n",
    "        return translation_dict[text]\n",
    "    else:\n",
    "        return text  # If the word is not in the translation dictionary, use the original text\n",
    "\n",
    "def convert_text_to_image(text, background_color=(0, 0, 0, 0)):\n",
    "    # Load the specified font\n",
    "    font = ImageFont.truetype(font_path, font_size)\n",
    "\n",
    "    # Create a new image with a transparent background\n",
    "    image = Image.new('RGBA', (1, 1), background_color)\n",
    "\n",
    "    # Create a draw object\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    # Calculate the text size\n",
    "    text_width, text_height = draw.textsize(text, font=font)\n",
    "\n",
    "    # Add some padding to the text size\n",
    "    padding = 10\n",
    "    image_width = text_width + padding\n",
    "    image_height = text_height + padding\n",
    "\n",
    "    # Create a new image with the adjusted dimensions and background color\n",
    "    image = Image.new('RGBA', (image_width, image_height), background_color)\n",
    "\n",
    "    # Create a new draw object with the adjusted image\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    # Calculate the position to place the text at the bottom of the image\n",
    "    text_x = (image.width - text_width) // 2\n",
    "    text_y = image.height - text_height - padding\n",
    "\n",
    "    # Draw the text on the image\n",
    "    draw.text((text_x, text_y), text, font=font, fill=font_color)\n",
    "\n",
    "    # Convert the PIL image to RGB mode\n",
    "    image = image.convert(\"RGB\")\n",
    "\n",
    "    # Convert the PIL image to a NumPy array\n",
    "    image_array = np.array(image)\n",
    "\n",
    "    return image_array\n",
    "\n",
    "def get_arabic_text(text):\n",
    "    reshaped_text = arabic_reshaper.reshape(text)\n",
    "    bidi_text = get_display(reshaped_text)\n",
    "    return bidi_text\n",
    "\n",
    "def overlay_text_on_frame(frame, words):\n",
    "    padding = 10\n",
    "    text_widths = []\n",
    "    text_heights = []\n",
    "\n",
    "    # Calculate the dimensions of each text image\n",
    "    for word in words:\n",
    "        text_image = convert_text_to_image(word)\n",
    "        text_width, text_height = text_image.shape[1], text_image.shape[0]\n",
    "        text_widths.append(text_width)\n",
    "        text_heights.append(text_height)\n",
    "\n",
    "    y = frame.shape[0] - sum(text_heights) - (padding * len(words))\n",
    "\n",
    "    if len(text_widths) > 0:\n",
    "        max_width = max(text_widths)\n",
    "        max_height = max(text_heights)\n",
    "    else:\n",
    "        max_width = 0\n",
    "        max_height = 0\n",
    "\n",
    "    x = (frame.shape[1] - max_width) // 2\n",
    "\n",
    "    for word, width, height in zip(words, text_widths, text_heights):\n",
    "        text_image = convert_text_to_image(word)\n",
    "        frame[y:y + height, x:x + width] = text_image\n",
    "        y += height + padding\n",
    "\n",
    "        # Check if the formed sentence is in the word dictionary\n",
    "        if formed_sentence in word_dictionary:\n",
    "            word_combinations[formed_sentence] = True\n",
    "\n",
    "    # Add the combined words to the list of words\n",
    "    combined_words = ' '.join(words)\n",
    "    combined_words_image = convert_text_to_image(combined_words)\n",
    "    combined_words_width, combined_words_height = combined_words_image.shape[1], combined_words_image.shape[0]\n",
    "\n",
    "    # Calculate the position to place the combined words\n",
    "    combined_words_x = (frame.shape[1] - combined_words_width) // 2\n",
    "    combined_words_y = y + max_height + padding\n",
    "\n",
    "    # Overlay the combined words on the frame\n",
    "    frame[combined_words_y:combined_words_y + combined_words_height, combined_words_x:combined_words_x + combined_words_width] = combined_words_image\n",
    "\n",
    "    return frame\n",
    "\n",
    "word_combinations = {}\n",
    "\n",
    "def detect_objects(frame):\n",
    "    results = yolo_model(frame)\n",
    "\n",
    "    if isinstance(results, list):\n",
    "        # Handle the case when results is a list\n",
    "        results = results[0]\n",
    "\n",
    "    # Extract the bounding box coordinates and class labels\n",
    "    boxes = results.xyxy[:, :4].tolist()\n",
    "    labels = results.xyxy[:, -1].tolist()\n",
    "\n",
    "    # Filter out non-object classes and get their corresponding labels\n",
    "    object_labels = [translate_to_arabic(str(label)) for label in labels]\n",
    "\n",
    "    return boxes, object_labels\n",
    "\n",
    "def process_frame(frame):\n",
    "    # Convert the frame from BGR to RGB\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Detect objects in the frame\n",
    "    boxes, object_labels = detect_objects(rgb_frame)\n",
    "\n",
    "    # Create a list to store the detected objects\n",
    "    detected_objects = []\n",
    "\n",
    "    for label in object_labels:\n",
    "        # Add the label to the detected objects list\n",
    "        detected_objects.append(label)\n",
    "\n",
    "    # Combine the detected words into a sentence\n",
    "    formed_sentence = ' '.join(detected_objects)\n",
    "\n",
    "    # Overlay the formed sentence on the frame\n",
    "    frame_with_text = overlay_text_on_frame(frame, detected_objects)\n",
    "\n",
    "    return frame_with_text\n",
    "\n",
    "# Main loop\n",
    "while True:\n",
    "    # Read a frame from the video capture\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Process the frame\n",
    "    processed_frame = process_frame(frame)\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow('Frame', processed_frame)\n",
    "\n",
    "    # Check for key press\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d801d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import time\n",
    "import arabic_reshaper\n",
    "import cv2\n",
    "from bidi.algorithm import get_display\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "yolo_model = YOLO(\"/Users/mernaziad/Desktop/final_train/runs/detect/train/weights/best.pt\")  # Replace with the path to your YOLO model weights\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Define the font properties\n",
    "font_face = cv2.FONT_HERSHEY_SIMPLEX\n",
    "font_color = (255, 255, 255)\n",
    "thickness = 2\n",
    "font_path = \"/Users/mernaziad/PycharmProjects/GraduationProject/arabic_font.ttf\"  # Replace with the path to your Arabic font file\n",
    "font_size = 32\n",
    "font_scale = 1\n",
    "font_thickness = 2\n",
    "word_combinations = {}\n",
    "formed_sentence = \"\"\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Translation dictionary\n",
    "translation_dict = {\n",
    "    '0':'0',\n",
    "    '1':'1', \n",
    "    '2':'2', \n",
    "    '3':'3', \n",
    "    '4':'4', \n",
    "    '5':'5', \n",
    "    '6':'6', \n",
    "    '7':'7', \n",
    "    '8':'8', \n",
    "    '9':'9', \n",
    "    'ALIF':'أ', \n",
    "    'AYN':'ع', \n",
    "    'Atman lak 7aya sa3eeda' :'أتمنى لك حياة سعيدة', \n",
    "    'BAA':'ب', \n",
    "    'DAD':'ض', \n",
    "    'DELL':'د', \n",
    "    'DHAA':'ظ', \n",
    "    'DHELL':'ذ', \n",
    "    'FAA':'ف', \n",
    "    'GHAYN':'غ', \n",
    "    'HA':'هـ', \n",
    "    'HAA':'ح', \n",
    "    'JEEM':'ج', \n",
    "    'KAAF':'ك', \n",
    "    'KHAA':'خ', \n",
    "    'LAAM':'ل', \n",
    "    'MEEM':'م', \n",
    "    'QAAF':'ق', \n",
    "    'RAA':'ر', \n",
    "    'SAD':'ص', \n",
    "    'SEEN':'س', \n",
    "    'SHEEN':'ش', \n",
    "    'TA':'ت', \n",
    "    'TAA':'ط', \n",
    "    'THA':'ث', \n",
    "    'WAW':'و', \n",
    "    'YA':'ي', \n",
    "    'ZAY':'ز', \n",
    "    'bad':'سيء', \n",
    "    'del':'حذف', \n",
    "    'eqtibas':'اقتباس', \n",
    "    'good':'جيد', \n",
    "    'law sama7t':'لو سمحت', \n",
    "    'merhaba':'مرحبا', \n",
    "    'nothing':'لا شيء', \n",
    "    'o7ebok':'أحبك', \n",
    "    'oraqebak':'أراقبك', \n",
    "    'space':'مسافة', \n",
    "    'you':'أنت', \n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "def translate_to_arabic(text):\n",
    "    if text in translation_dict:\n",
    "        return translation_dict[text]\n",
    "    else:\n",
    "        return text  # If the word is not in the translation dictionary, use the original text\n",
    "\n",
    "def convert_text_to_image(text, background_color=(0, 0, 0, 0)):\n",
    "    # Load the specified font\n",
    "    font = ImageFont.truetype(font_path, font_size)\n",
    "\n",
    "    # Create a new image with a transparent background\n",
    "    image = Image.new('RGBA', (1, 1), background_color)\n",
    "\n",
    "    # Create a draw object\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    # Calculate the text size\n",
    "    text_width, text_height = draw.textsize(text, font=font)\n",
    "\n",
    "    # Add some padding to the text size\n",
    "    padding = 10\n",
    "    image_width = text_width + padding\n",
    "    image_height = text_height + padding\n",
    "\n",
    "\n",
    "    # Create a new image with the adjusted dimensions and background color\n",
    "    image = Image.new('RGBA', (image_width, image_height), background_color)\n",
    "\n",
    "    # Create a new draw object with the adjusted image\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    # Calculate the position to place the text at the bottom of the image\n",
    "    text_x = (image.width - text_width) // 2\n",
    "    text_y = image.height - text_height - padding\n",
    "\n",
    "    # Draw the text on the image\n",
    "    draw.text((text_x, text_y), text, font=font, fill=font_color)\n",
    "\n",
    "    # Convert the PIL image to RGB mode\n",
    "    image = image.convert(\"RGB\")\n",
    "\n",
    "    # Convert the PIL image to a NumPy array\n",
    "    image_array = np.array(image)\n",
    "\n",
    "    return image_array\n",
    "\n",
    "def get_arabic_text(text):\n",
    "    reshaped_text = arabic_reshaper.reshape(text)\n",
    "    bidi_text = get_display(reshaped_text)\n",
    "    return bidi_text\n",
    "\n",
    "# Define the dictionary of combinable words\n",
    "combinable_words = {\n",
    "    'ALEFBAAYAA': 'أبي',\n",
    "    'ALEFBAA': 'أب',\n",
    "   \n",
    "}\n",
    "\n",
    "def overlay_text_on_frame(frame, words):\n",
    "    padding = 10\n",
    "    text_heights = []\n",
    "\n",
    "    # Calculate the dimensions of each text image\n",
    "    for word in words:\n",
    "        if word in combinable_words:\n",
    "            text = combinable_words[word]\n",
    "            text_image = convert_text_to_image(text)\n",
    "        else:\n",
    "            text = word\n",
    "            text_image = convert_text_to_image(word)\n",
    "        \n",
    "        text_height = text_image.shape[0]\n",
    "        text_heights.append(text_height)\n",
    "\n",
    "    if len(text_heights) == 0:\n",
    "        return frame\n",
    "\n",
    "    y = frame.shape[0] - sum(text_heights) - (padding * len(words))\n",
    "    x = (frame.shape[1] - max([convert_text_to_image(word).shape[1] for word in words])) // 2\n",
    "\n",
    "    for word in words:\n",
    "        if word in combinable_words:\n",
    "            text = combinable_words[word]\n",
    "            text_image = convert_text_to_image(text)\n",
    "        else:\n",
    "            text = word\n",
    "            text_image = convert_text_to_image(word)\n",
    "\n",
    "        frame[y:y + text_image.shape[0], x:x + text_image.shape[1]] = text_image\n",
    "        y += text_image.shape[0] + padding\n",
    "\n",
    "    return frame\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def detect_objects(frame):\n",
    "    global formed_sentence, word_combinations\n",
    "\n",
    "    results = yolo_model.predict(frame)\n",
    "    result = results[0]\n",
    "    frame_with_text = frame.copy()\n",
    "\n",
    "    for box in results[0].boxes:\n",
    "        cords = box.xyxy[0].tolist()\n",
    "        cords = [round(x) for x in cords]\n",
    "        class_id = result.names[box.cls[0].item()]\n",
    "        translated_text = translate_to_arabic(class_id)\n",
    "        expected_text = get_arabic_text(translated_text)\n",
    "\n",
    "        conf = round(box.conf[0].item(), 2)\n",
    "\n",
    "        if conf < 0.5:\n",
    "            continue\n",
    "\n",
    "        text_image = convert_text_to_image(expected_text)\n",
    "        frame_with_text = overlay_text_on_frame(frame_with_text, list(word_combinations.keys()))\n",
    "\n",
    "        if translated_text != \"\":\n",
    "            formed_sentence += translated_text\n",
    "            if len(formed_sentence) >= 2:  # Check if there are at least two characters in the formed sentence\n",
    "                word_combinations[formed_sentence] = True\n",
    "                formed_sentence = \"\"  # Reset the formed sentence for the next combination\n",
    "\n",
    "    # Display the modified frame\n",
    "    cv2.imshow(\"Object Detection\", frame_with_text)\n",
    "\n",
    "def process_frames():\n",
    "    ret, frame = cap.read()\n",
    "    if frame.shape[:2] != (800, 600):\n",
    "        frame = cv2.resize(frame, (800, 600))\n",
    "    \n",
    "    # Perform object detection and modification on the frame\n",
    "    detect_objects(frame)\n",
    "\n",
    "    if len(word_combinations) > 0:\n",
    "        frame_with_text = overlay_text_on_frame(frame, list(word_combinations.keys()))\n",
    "    else:\n",
    "        frame_with_text = frame\n",
    "\n",
    "    # Display the modified frame\n",
    "    cv2.imshow(\"Object Detection\", frame_with_text)\n",
    "\n",
    "    # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "while True:\n",
    "    if not process_frames():\n",
    "        break\n",
    "\n",
    "# Release the video capture and close the window\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Combine the words from the dictionary\n",
    "combined_words = ' '.join(word_combinations.keys())\n",
    "print(\"Combined Words:\", combined_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28151f13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711bed6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import time\n",
    "import arabic_reshaper\n",
    "import cv2\n",
    "from bidi.algorithm import get_display\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "yolo_model = YOLO(\"/Users/mernaziad/Desktop/final_train/runs/detect/train/weights/best.pt\")  # Replace with the path to your YOLO model weights\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Define the font properties\n",
    "font_face = cv2.FONT_HERSHEY_SIMPLEX\n",
    "font_color = (255, 255, 255)\n",
    "thickness = 2\n",
    "font_path = \"/Users/mernaziad/PycharmProjects/GraduationProject/arabic_font.ttf\"  # Replace with the path to your Arabic font file\n",
    "font_size = 32\n",
    "font_scale = 1\n",
    "font_thickness = 2\n",
    "word_combinations = {}\n",
    "formed_sentence = \"\"\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Translation dictionary\n",
    "translation_dict = {\n",
    "    '0':'0',\n",
    "    '1':'1', \n",
    "    '2':'2', \n",
    "    '3':'3', \n",
    "    '4':'4', \n",
    "    '5':'5', \n",
    "    '6':'6', \n",
    "    '7':'7', \n",
    "    '8':'8', \n",
    "    '9':'9', \n",
    "    'ALIF':'أ', \n",
    "    'AYN':'ع', \n",
    "    'Atman lak 7aya sa3eeda' :'أتمنى لك حياة سعيدة', \n",
    "    'BAA':'ب', \n",
    "    'DAD':'ض', \n",
    "    'DELL':'د', \n",
    "    'DHAA':'ظ', \n",
    "    'DHELL':'ذ', \n",
    "    'FAA':'ف', \n",
    "    'GHAYN':'غ', \n",
    "    'HA':'هـ', \n",
    "    'HAA':'ح', \n",
    "    'JEEM':'ج', \n",
    "    'KAAF':'ك', \n",
    "    'KHAA':'خ', \n",
    "    'LAAM':'ل', \n",
    "    'MEEM':'م', \n",
    "    'QAAF':'ق', \n",
    "    'RAA':'ر', \n",
    "    'SAD':'ص', \n",
    "    'SEEN':'س', \n",
    "    'SHEEN':'ش', \n",
    "    'TA':'ت', \n",
    "    'TAA':'ط', \n",
    "    'THA':'ث', \n",
    "    'WAW':'و', \n",
    "    'YA':'ي', \n",
    "    'ZAY':'ز', \n",
    "    'bad':'سيء', \n",
    "    'del':'حذف', \n",
    "    'eqtibas':'اقتباس', \n",
    "    'good':'جيد', \n",
    "    'law sama7t':'لو سمحت', \n",
    "    'merhaba':'مرحبا', \n",
    "    'nothing':'لا شيء', \n",
    "    'o7ebok':'أحبك', \n",
    "    'oraqebak':'أراقبك', \n",
    "    'space':'مسافة', \n",
    "    'you':'أنت', \n",
    "}\n",
    "\n",
    "def translate_to_arabic(text):\n",
    "    if text in translation_dict:\n",
    "        return translation_dict[text]\n",
    "    else:\n",
    "        return text  # If the word is not in the translation dictionary, use the original text\n",
    "\n",
    "def convert_text_to_image(text, background_color=(0, 0, 0, 0)):\n",
    "    # Load the specified font\n",
    "    font = ImageFont.truetype(font_path, font_size)\n",
    "\n",
    "    # Create a new image with a transparent background\n",
    "    image = Image.new('RGBA', (1, 1), background_color)\n",
    "\n",
    "    # Create a draw object\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    # Calculate the text size\n",
    "    text_width, text_height = draw.textsize(text, font=font)\n",
    "\n",
    "    # Add some padding to the text size\n",
    "    padding = 10\n",
    "    image_width = text_width + padding\n",
    "    image_height = text_height + padding\n",
    "\n",
    "    # Create a new image with the adjusted dimensions and background color\n",
    "    image = Image.new('RGBA', (image_width, image_height), background_color)\n",
    "\n",
    "    # Create a new draw object with the adjusted image\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    # Calculate the position to place the text at the bottom of the image\n",
    "    text_x = (image.width - text_width) // 2\n",
    "    text_y = image.height - text_height - padding\n",
    "\n",
    "    # Draw the text on the image\n",
    "    draw.text((text_x, text_y), text, font=font, fill=font_color)\n",
    "\n",
    "    # Convert the PIL image to RGB mode\n",
    "    image = image.convert(\"RGB\")\n",
    "\n",
    "    # Convert the PIL image to a NumPy array\n",
    "    image_array = np.array(image)\n",
    "\n",
    "    return image_array\n",
    "\n",
    "def get_arabic_text(text):\n",
    "    reshaped_text = arabic_reshaper.reshape(text)\n",
    "    bidi_text = get_display(reshaped_text)\n",
    "    return bidi_text\n",
    "\n",
    "# Define the dictionary of combinable words\n",
    "combinable_words = {\n",
    "    'أ': 'أبي',\n",
    "    'ب': 'أبي',\n",
    "    'ي': 'أبي',\n",
    "    # يمكنك إضافة المزيد من الكلمات المركبة هنا\n",
    "}\n",
    "\n",
    "def overlay_text_on_frame(frame, words):\n",
    "    padding = 10\n",
    "    text_heights = []\n",
    "\n",
    "    # Calculate the dimensions of each text image\n",
    "    for word in words:\n",
    "        if word in combinable_words:\n",
    "            text = combinable_words[word]\n",
    "            text_image = convert_text_to_image(text)\n",
    "        else:\n",
    "            text = word\n",
    "            text_image = convert_text_to_image(word)\n",
    "\n",
    "        text_height = text_image.shape[0]\n",
    "        text_heights.append(text_height)\n",
    "\n",
    "    if len(text_heights) == 0:\n",
    "        return frame\n",
    "\n",
    "    y = frame.shape[0] - sum(text_heights) - (padding * len(words))\n",
    "    x = (frame.shape[1] - max([convert_text_to_image(word).shape[1] for word in words])) // 2\n",
    "\n",
    "    for word in words:\n",
    "        if word in combinable_words:\n",
    "            text = combinable_words[word]\n",
    "            text_image = convert_text_to_image(text)\n",
    "        else:\n",
    "            text = word\n",
    "            text_image = convert_text_to_image(word)\n",
    "\n",
    "        frame[y:y + text_image.shape[0], x:x + text_image.shape[1]] = text_image\n",
    "        y += text_image.shape[0] + padding\n",
    "\n",
    "    return frame\n",
    "\n",
    "def detect_objects(frame):\n",
    "    global formed_sentence, word_combinations\n",
    "\n",
    "    results = yolo_model.predict(frame)\n",
    "    result = results[0]\n",
    "    frame_with_text = frame.copy()\n",
    "\n",
    "    for box in results[0].boxes:\n",
    "        cords = box.xyxy[0].tolist()\n",
    "        cords = [round(x) for x in cords]\n",
    "        class_id = result.names[box.cls[0].item()]\n",
    "        translated_text = translate_to_arabic(class_id)\n",
    "        expected_text = get_arabic_text(translated_text)\n",
    "\n",
    "        conf = round(box.conf[0].item(), 2)\n",
    "\n",
    "        if conf < 0.5:\n",
    "            continue\n",
    "\n",
    "        text_image = convert_text_to_image(expected_text)\n",
    "        frame_with_text = overlay_text_on_frame(frame_with_text, list(word_combinations.keys()))\n",
    "\n",
    "#         if translated_text != \"\":\n",
    "#             formed_sentence += translated_text\n",
    "#             if len(formed_sentence) >= 2:  # Check if there are at least two characters in the formed sentence\n",
    "#                 word_combinations[formed_sentence] = True\n",
    "#                 formed_sentence = \"\"  # Reset the formed sentence for the next combination\n",
    "        if translated_text and translated_text in word_combinations:\n",
    "            formed_sentence += translated_text\n",
    "            if len(formed_sentence) >= 2:\n",
    "                word_combinations[formed_sentence] = True\n",
    "                formed_sentence = \"\"\n",
    "    # Display the modified frame\n",
    "    cv2.imshow(\"Object Detection\", frame_with_text)\n",
    "\n",
    "def process_frames():\n",
    "    ret, frame = cap.read()\n",
    "    if frame.shape[:2] != (800, 600):\n",
    "        frame = cv2.resize(frame, (800, 600))\n",
    "    \n",
    "    # Perform object detection and modification on the frame\n",
    "    detect_objects(frame)\n",
    "\n",
    "    if len(word_combinations) > 0:\n",
    "        frame_with_text = overlay_text_on_frame(frame, list(word_combinations.keys()))\n",
    "    else:\n",
    "        frame_with_text = frame\n",
    "\n",
    "    # Display the modified frame\n",
    "    cv2.imshow(\"Object Detection\", frame_with_text)\n",
    "\n",
    "    # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "while True:\n",
    "    if not process_frames():\n",
    "        break\n",
    "\n",
    "# Release the video capture and close the window\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Combine the words from the dictionary\n",
    "combined_words = ' '.join(word_combinations.keys())\n",
    "print(\"Combined Words:\", combined_words)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3197e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import time\n",
    "import arabic_reshaper\n",
    "import cv2\n",
    "from bidi.algorithm import get_display\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "yolo_model = YOLO(\"/Users/mernaziad/Desktop/final_train/runs/detect/train/weights/best.pt\")  # Replace with the path to your YOLO model weights\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Define the font properties\n",
    "font_face = cv2.FONT_HERSHEY_SIMPLEX\n",
    "font_color = (255, 255, 255)\n",
    "thickness = 2\n",
    "font_path = \"/Users/mernaziad/PycharmProjects/GraduationProject/arabic_font.ttf\"  # Replace with the path to your Arabic font file\n",
    "font_size = 32\n",
    "font_scale = 1\n",
    "font_thickness = 2\n",
    "word_combinations = {}\n",
    "formed_sentence = \"\"\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Translation dictionary\n",
    "translation_dict = {\n",
    "    '0':'0',\n",
    "    '1':'1', \n",
    "    '2':'2', \n",
    "    '3':'3', \n",
    "    '4':'4', \n",
    "    '5':'5', \n",
    "    '6':'6', \n",
    "    '7':'7', \n",
    "    '8':'8', \n",
    "    '9':'9', \n",
    "    'ALIF':'أ', \n",
    "    'AYN':'ع', \n",
    "    'Atman lak 7aya sa3eeda' :'أتمنى لك حياة سعيدة', \n",
    "    'BAA':'ب', \n",
    "    'DAD':'ض', \n",
    "    'DELL':'د', \n",
    "    'DHAA':'ظ', \n",
    "    'DHELL':'ذ', \n",
    "    'FAA':'ف', \n",
    "    'GHAYN':'غ', \n",
    "    'HA':'هـ', \n",
    "    'HAA':'ح', \n",
    "    'JEEM':'ج', \n",
    "    'KAAF':'ك', \n",
    "    'KHAA':'خ', \n",
    "    'LAAM':'ل', \n",
    "    'MEEM':'م', \n",
    "    'QAAF':'ق', \n",
    "    'RAA':'ر', \n",
    "    'SAD':'ص', \n",
    "    'SEEN':'س', \n",
    "    'SHEEN':'ش', \n",
    "    'TA':'ت', \n",
    "    'TAA':'ط', \n",
    "    'THA':'ث', \n",
    "    'WAW':'و', \n",
    "    'YA':'ي', \n",
    "    'ZAY':'ز', \n",
    "    'bad':'سيء', \n",
    "    'del':'حذف', \n",
    "    'eqtibas':'اقتباس', \n",
    "    'good':'جيد', \n",
    "    'law sama7t':'لو سمحت', \n",
    "    'merhaba':'مرحبا', \n",
    "    'nothing':'لا شيء', \n",
    "    'o7ebok':'أحبك', \n",
    "    'oraqebak':'أراقبك', \n",
    "    'space':'مسافة', \n",
    "    'you':'أنت', \n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "def translate_to_arabic(text):\n",
    "    if text in translation_dict:\n",
    "        return translation_dict[text]\n",
    "    else:\n",
    "        return text  # If the word is not in the translation dictionary, use the original text\n",
    "\n",
    "def convert_text_to_image(text, background_color=(0, 0, 0, 0)):\n",
    "    # Load the specified font\n",
    "    font = ImageFont.truetype(font_path, font_size)\n",
    "\n",
    "    # Create a new image with a transparent background\n",
    "    image = Image.new('RGBA', (1, 1), background_color)\n",
    "\n",
    "    # Create a draw object\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    # Calculate the text size\n",
    "    text_width, text_height = draw.textsize(text, font=font)\n",
    "\n",
    "    # Add some padding to the text size\n",
    "    padding = 10\n",
    "    image_width = text_width + padding\n",
    "    image_height = text_height + padding\n",
    "\n",
    "\n",
    "    # Create a new image with the adjusted dimensions and background color\n",
    "    image = Image.new('RGBA', (image_width, image_height), background_color)\n",
    "\n",
    "    # Create a new draw object with the adjusted image\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    # Calculate the position to place the text at the bottom of the image\n",
    "    text_x = (image.width - text_width) // 2\n",
    "    text_y = image.height - text_height - padding\n",
    "\n",
    "    # Draw the text on the image\n",
    "    draw.text((text_x, text_y), text, font=font, fill=font_color)\n",
    "\n",
    "    # Convert the PIL image to RGB mode\n",
    "    image = image.convert(\"RGB\")\n",
    "\n",
    "    # Convert the PIL image to a NumPy array\n",
    "    image_array = np.array(image)\n",
    "\n",
    "    return image_array\n",
    "\n",
    "def get_arabic_text(text):\n",
    "    reshaped_text = arabic_reshaper.reshape(text)\n",
    "    bidi_text = get_display(reshaped_text)\n",
    "    return bidi_text\n",
    "\n",
    "# Define the dictionary of combinable words\n",
    "combinable_words = {\n",
    "    'أبي':'True',\n",
    "    'أب':'True'\n",
    "}\n",
    "\n",
    "def overlay_text_on_frame(frame, words):\n",
    "    padding = 10\n",
    "    text_heights = []\n",
    "\n",
    "    # Calculate the total width and height of all the text\n",
    "    total_text_width = 0\n",
    "    max_text_height = 0\n",
    "    for word in words:\n",
    "        if word in combinable_words:\n",
    "            text = combinable_words[word]\n",
    "            text_image = convert_text_to_image(text)\n",
    "        else:\n",
    "            text = word\n",
    "            text_image = convert_text_to_image(word)\n",
    "\n",
    "        text_height = text_image.shape[0]\n",
    "        text_heights.append(text_height)\n",
    "\n",
    "        total_text_width += text_image.shape[1] + padding\n",
    "        max_text_height = max(max_text_height, text_height)\n",
    "\n",
    "    # Calculate the starting position to center the text\n",
    "    x = (frame.shape[1] - total_text_width) // 2\n",
    "    y = frame.shape[0] - max_text_height - padding\n",
    "\n",
    "    for word in words:\n",
    "        if word in combinable_words:\n",
    "            text = combinable_words[word]\n",
    "            text_image = convert_text_to_image(text)\n",
    "        else:\n",
    "            text = word\n",
    "            text_image = convert_text_to_image(word)\n",
    "\n",
    "        frame[y:y + text_image.shape[0], x:x + text_image.shape[1]] = text_image\n",
    "        x += text_image.shape[1] + padding\n",
    "\n",
    "    return frame\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def detect_objects(frame):\n",
    "    global formed_sentence, word_combinations\n",
    "\n",
    "    results = yolo_model.predict(frame)\n",
    "    result = results[0]\n",
    "    frame_with_text = frame.copy()\n",
    "\n",
    "    for box in results[0].boxes:\n",
    "        cords = box.xyxy[0].tolist()\n",
    "        cords = [round(x) for x in cords]\n",
    "        class_id = result.names[box.cls[0].item()]\n",
    "        translated_text = translate_to_arabic(class_id)\n",
    "        expected_text = get_arabic_text(translated_text)\n",
    "\n",
    "        conf = round(box.conf[0].item(), 2)\n",
    "\n",
    "        if conf < 0.5:\n",
    "            continue\n",
    "\n",
    "        text_image = convert_text_to_image(expected_text)\n",
    "        frame_with_text = overlay_text_on_frame(frame_with_text, list(word_combinations.keys()))\n",
    "\n",
    "        if translated_text != \"\":\n",
    "            formed_sentence += translated_text\n",
    "            if len(formed_sentence) >= 2:  # Check if there are at least two characters in the formed sentence\n",
    "                word_combinations[formed_sentence] = True\n",
    "                formed_sentence = \"\"  # Reset the formed sentence for the next combination\n",
    "\n",
    "    # Display the modified frame\n",
    "    cv2.imshow(\"Object Detection\", frame_with_text)\n",
    "\n",
    "def process_frames():\n",
    "    ret, frame = cap.read()\n",
    "    if frame.shape[:2] != (800, 600):\n",
    "        frame = cv2.resize(frame, (800, 600))\n",
    "    \n",
    "    # Perform object detection and modification on the frame\n",
    "    detect_objects(frame)\n",
    "\n",
    "    if len(word_combinations) > 0:\n",
    "        frame_with_text = overlay_text_on_frame(frame, list(word_combinations.keys()))\n",
    "    else:\n",
    "        frame_with_text = frame\n",
    "\n",
    "    # Display the modified frame\n",
    "    cv2.imshow(\"Object Detection\", frame_with_text)\n",
    "\n",
    "    # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "while True:\n",
    "    if not process_frames():\n",
    "        break\n",
    "\n",
    "# Release the video capture and close the window\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Combine the words from the dictionary\n",
    "combined_words = ' '.join(word_combinations.keys())\n",
    "print(\"Combined Words:\", combined_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6405f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import time\n",
    "import arabic_reshaper\n",
    "import cv2\n",
    "from bidi.algorithm import get_display\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "yolo_model = YOLO(\"/Users/mernaziad/Desktop/final_train/runs/detect/train/weights/best.pt\")  # Replace with the path to your YOLO model weights\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Define the font properties\n",
    "font_face = cv2.FONT_HERSHEY_SIMPLEX\n",
    "font_color = (255, 255, 255)\n",
    "thickness = 2\n",
    "font_path = \"/Users/mernaziad/PycharmProjects/GraduationProject/arabic_font.ttf\"  # Replace with the path to your Arabic font file\n",
    "font_size = 32\n",
    "font_scale = 1\n",
    "font_thickness = 2\n",
    "word_combinations = {}\n",
    "formed_word = \"\"\n",
    "time_threshold = 5  # Time threshold in seconds\n",
    "last_char_time = time.time()\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Translation dictionary\n",
    "translation_dict = {\n",
    "    '0': '0',\n",
    "    '1': '1',\n",
    "    '2': '2',\n",
    "    '3': '3',\n",
    "    '4': '4',\n",
    "    '5': '5',\n",
    "    '6': '6',\n",
    "    '7': '7',\n",
    "    '8': '8',\n",
    "    '9': '9',\n",
    "    'ALIF': 'أ',\n",
    "    'AYN': 'ع',\n",
    "    'Atman lak 7aya sa3eeda': 'أتمنى لك حياة سعيدة',\n",
    "    'BAA': 'ب',\n",
    "    'DAD': 'ض',\n",
    "    'DELL': 'د',\n",
    "    'DHAA': 'ظ',\n",
    "    'DHELL': 'ذ',\n",
    "    'FAA': 'ف',\n",
    "    'GHAYN': 'غ',\n",
    "    'HA': 'هـ',\n",
    "    'HAA': 'ح',\n",
    "    'JEEM': 'ج',\n",
    "    'KAAF': 'ك',\n",
    "    'KHAA': 'خ',\n",
    "    'LAAM': 'ل',\n",
    "    'MEEM': 'م',\n",
    "    'QAAF': 'ق',\n",
    "    'RAA': 'ر',\n",
    "    'SAD': 'ص',\n",
    "    'SEEN': 'س',\n",
    "    'SHEEN': 'ش',\n",
    "    'TA': 'ت',\n",
    "    'TAA': 'ط',\n",
    "    'THA': 'ث',\n",
    "    'WAW': 'و',\n",
    "    'YA': 'ي',\n",
    "    'ZAY': 'ز',\n",
    "    'bad': 'سيء',\n",
    "    'del': 'حذف',\n",
    "    'eqtibas': 'اقتباس',\n",
    "    'good': 'جيد',\n",
    "    'law sama7t': 'لو سمحت',\n",
    "    'merhaba': 'مرحبا',\n",
    "    'nothing': 'لا شيء',\n",
    "    'o7ebok': 'أحبك',\n",
    "    'oraqebak': 'أراقبك',\n",
    "    'space': 'مسافة',\n",
    "    'you': 'أنت',\n",
    "}\n",
    "\n",
    "# Define the dictionary of combinable words\n",
    "combinable_words = {\n",
    "    'أبي': 'أ ب ي',\n",
    "    'أمي': 'أ م ي',\n",
    "    'أخي': 'أ خ ي',\n",
    "    'أختي': 'أ خ ت ي',\n",
    "    # إضافة المزيد من الكلمات المجمعة هنا\n",
    "}\n",
    "def translate_to_arabic(text):\n",
    "    if text in translation_dict:\n",
    "        return translation_dict[text]\n",
    "    else:\n",
    "        return text  # If the word is not in the translation dictionary, use the original text\n",
    "    \n",
    "def get_arabic_text(text):\n",
    "    reshaped_text = arabic_reshaper.reshape(text)\n",
    "    bidi_text = get_display(reshaped_text)\n",
    "    return bidi_text\n",
    "\n",
    "\n",
    "def convert_text_to_image(text):\n",
    "    reshaped_text = arabic_reshaper.reshape(text)\n",
    "    bidi_text = get_display(reshaped_text)\n",
    "    font = ImageFont.truetype(font_path, font_size)\n",
    "    text_width, text_height = font.getsize(bidi_text)\n",
    "    image = Image.new('RGB', (text_width, text_height), color=(0, 0, 0))\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    draw.text((0, 0), bidi_text, font=font, fill=(255, 255, 255))\n",
    "    return np.array(image)\n",
    "\n",
    "def overlay_text_on_frame(frame, words):\n",
    "    padding = 10\n",
    "    total_text_width = 0\n",
    "    max_text_height = 0\n",
    "\n",
    "    # Combine only the relevant words\n",
    "    relevant_words = [word for word in words if word in combinable_words]\n",
    "\n",
    "    for word in relevant_words:\n",
    "        text_image = convert_text_to_image(combinable_words[word])\n",
    "        total_text_width += text_image.shape[1] + padding\n",
    "        max_text_height = max(max_text_height, text_image.shape[0])\n",
    "\n",
    "    # Calculate the starting x position to center the text\n",
    "    x = (frame.shape[1] - total_text_width) // 2\n",
    "    y = frame.shape[0] - max_text_height - padding\n",
    "\n",
    "    for word in relevant_words:\n",
    "        text_image = convert_text_to_image(combinable_words[word])\n",
    "        frame[y:y + text_image.shape[0], x:x + text_image.shape[1]] = text_image\n",
    "        x += text_image.shape[1] + padding\n",
    "\n",
    "    return frame\n",
    "\n",
    "def detect_objects(frame):\n",
    "    global formed_word, last_char_time\n",
    "\n",
    "    # Convert the frame to PIL Image format\n",
    "    pil_image = Image.fromarray(frame)\n",
    "\n",
    "    # Perform object detection using YOLO\n",
    "    results = yolo_model(pil_image)\n",
    "    results = yolo_model.predict(frame)\n",
    "    result = results[0]\n",
    "    frame_with_text = frame.copy()\n",
    "\n",
    "    for box in results[0].boxes:\n",
    "        cords = box.xyxy[0].tolist()\n",
    "        cords = [round(x) for x in cords]\n",
    "        class_id = result.names[box.cls[0].item()]\n",
    "        translated_text = translate_to_arabic(class_id)\n",
    "        expected_text = get_arabic_text(translated_text)\n",
    "\n",
    "        conf = round(box.conf[0].item(), 2)\n",
    "\n",
    "        if conf > 0.5:\n",
    "            formed_word += translated_text\n",
    "\n",
    "            # Check if enough time has passed since the last character\n",
    "            if time.time() - last_char_time > time_threshold:\n",
    "                if formed_word in combinable_words:\n",
    "                    formed_word = combinable_words[formed_word]\n",
    "                word_combinations[formed_word] = True\n",
    "                formed_word = \"\"\n",
    "\n",
    "            last_char_time = time.time()\n",
    "\n",
    "\n",
    "def process_frames():\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        return False\n",
    "\n",
    "    frame = cv2.resize(frame, (800, 600))\n",
    "\n",
    "    detect_objects(frame)\n",
    "\n",
    "    if len(word_combinations) > 0:\n",
    "        frame_with_text = overlay_text_on_frame(frame, list(word_combinations.keys()))\n",
    "        cv2.imshow('Frame', frame_with_text)\n",
    "    else:\n",
    "        cv2.imshow('Frame', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "while True:\n",
    "    if not process_frames():\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c05db1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import time\n",
    "import arabic_reshaper\n",
    "import cv2\n",
    "from bidi.algorithm import get_display\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "yolo_model = YOLO(\"/Users/mernaziad/Desktop/final_train/runs/detect/train/weights/best.pt\")  # Replace with the path to your YOLO model weights\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Define the font properties\n",
    "font_face = cv2.FONT_HERSHEY_SIMPLEX\n",
    "font_color = (255, 255, 255)\n",
    "thickness = 2\n",
    "font_path = \"/Users/mernaziad/PycharmProjects/GraduationProject/arabic_font.ttf\"  # Replace with the path to your Arabic font file\n",
    "font_size = 32\n",
    "font_scale = 1\n",
    "font_thickness = 2\n",
    "word_combinations = {}\n",
    "formed_sentence = \"\"\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Translation dictionary\n",
    "translation_dict = {\n",
    "    '0':'0',\n",
    "    '1':'1', \n",
    "    '2':'2', \n",
    "    '3':'3', \n",
    "    '4':'4', \n",
    "    '5':'5', \n",
    "    '6':'6', \n",
    "    '7':'7', \n",
    "    '8':'8', \n",
    "    '9':'9', \n",
    "    'ALIF':'أ', \n",
    "    'AYN':'ع', \n",
    "    'Atman lak 7aya sa3eeda' :'أتمنى لك حياة سعيدة', \n",
    "    'BAA':'ب', \n",
    "    'DAD':'ض', \n",
    "    'DELL':'د', \n",
    "    'DHAA':'ظ', \n",
    "    'DHELL':'ذ', \n",
    "    'FAA':'ف', \n",
    "    'GHAYN':'غ', \n",
    "    'HA':'هـ', \n",
    "    'HAA':'ح', \n",
    "    'JEEM':'ج', \n",
    "    'KAAF':'ك', \n",
    "    'KHAA':'خ', \n",
    "    'LAAM':'ل', \n",
    "    'MEEM':'م', \n",
    "    'QAAF':'ق', \n",
    "    'RAA':'ر', \n",
    "    'SAD':'ص', \n",
    "    'SEEN':'س', \n",
    "    'SHEEN':'ش', \n",
    "    'TA':'ت', \n",
    "    'TAA':'ط', \n",
    "    'THA':'ث', \n",
    "    'WAW':'و', \n",
    "    'YA':'ي', \n",
    "    'ZAY':'ز', \n",
    "    'bad':'سيء', \n",
    "    'del':'حذف', \n",
    "    'eqtibas':'اقتباس', \n",
    "    'good':'جيد', \n",
    "    'law sama7t':'لو سمحت', \n",
    "    'merhaba':'مرحبا', \n",
    "    'nothing':'لا شيء', \n",
    "    'o7ebok':'أحبك', \n",
    "    'oraqebak':'أراقبك', \n",
    "    'space':'مسافة', \n",
    "    'you':'أنت', \n",
    "}\n",
    "\n",
    "def translate_to_arabic(text):\n",
    "    if text in translation_dict:\n",
    "        return translation_dict[text]\n",
    "    else:\n",
    "        return text  # If the word is not in the translation dictionary, use the original text\n",
    "\n",
    "def convert_text_to_image(text, background_color=(0, 0, 0, 0)):\n",
    "    # Load the specified font\n",
    "    font = ImageFont.truetype(font_path, font_size)\n",
    "\n",
    "    # Create a new image with a transparent background\n",
    "    image = Image.new('RGBA', (1, 1), background_color)\n",
    "\n",
    "    # Create a draw object\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    # Calculate the text size\n",
    "    text_width, text_height = draw.textsize(text, font=font)\n",
    "\n",
    "    # Add some padding to the text size\n",
    "    padding = 10\n",
    "    image_width = text_width + padding\n",
    "    image_height = text_height + padding\n",
    "\n",
    "    # Create a new image with the adjusted dimensions and background color\n",
    "    image = Image.new('RGBA', (image_width, image_height), background_color)\n",
    "\n",
    "    # Create a new draw object with the adjusted image\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    # Calculate the position to place the text at the bottom of the image\n",
    "    text_x = (image.width - text_width) // 2\n",
    "    text_y = image.height - text_height - padding\n",
    "\n",
    "    # Draw the text on the image\n",
    "    draw.text((text_x, text_y), text, font=font, fill=font_color)\n",
    "\n",
    "    # Convert the PIL image to RGB mode\n",
    "    image = image.convert(\"RGB\")\n",
    "\n",
    "    # Convert the PIL image to a NumPy array\n",
    "    image_array = np.array(image)\n",
    "\n",
    "    return image_array\n",
    "\n",
    "def get_arabic_text(text):\n",
    "    reshaped_text = arabic_reshaper.reshape(text)\n",
    "    bidi_text = get_display(reshaped_text)\n",
    "    return bidi_text\n",
    "\n",
    "# Define the dictionary of combinable words\n",
    "combinable_words = {\n",
    "    'ALEFBAAYAA': 'أبي',\n",
    "    'ALEFBAA': 'أب',\n",
    "}\n",
    "\n",
    "def overlay_text_on_frame(frame, words):\n",
    "    padding = 10\n",
    "    text_height = 0\n",
    "\n",
    "    # Calculate the total width of the text\n",
    "    for word in words:\n",
    "        if word in combinable_words:\n",
    "            text = combinable_words[word]\n",
    "            text_image = convert_text_to_image(text)\n",
    "        else:\n",
    "            text = word\n",
    "            text_image = convert_text_to_image(word)\n",
    "\n",
    "        text_height = max(text_height, text_image.shape[0])\n",
    "\n",
    "    if text_height == 0:\n",
    "        return frame\n",
    "\n",
    "    x = 0\n",
    "    frame_height, frame_width, _ = frame.shape\n",
    "\n",
    "    for word in words:\n",
    "        if word in combinable_words:\n",
    "            text = combinable_words[word]\n",
    "            text_image = convert_text_to_image(text)\n",
    "        else:\n",
    "            text = word\n",
    "            text_image = convert_text_to_image(word)\n",
    "\n",
    "        text_width = text_image.shape[1]\n",
    "        text_image = cv2.resize(text_image, (text_width, text_height))  # Resize the text image\n",
    "\n",
    "        text_image = np.pad(text_image, ((0, 0), (padding, padding), (0, 0)), constant_values=(0, 0))\n",
    "        text_image_height, text_image_width, _ = text_image.shape\n",
    "\n",
    "        if x + text_image_width > frame_width:\n",
    "            break\n",
    "\n",
    "        text_image = cv2.putText(text_image, text, (padding, text_image_height - padding),\n",
    "                                 font_face, font_scale, font_color, thickness, cv2.LINE_AA)\n",
    "\n",
    "        frame[text_height:, x:x + text_image_width] = text_image\n",
    "        x += text_image_width\n",
    "\n",
    "    return frame\n",
    "\n",
    "\n",
    "def detect_objects(frame):\n",
    "    global formed_sentence, word_combinations\n",
    "\n",
    "    results = yolo_model.predict(frame)\n",
    "    result = results[0]\n",
    "    frame_with_text = frame.copy()\n",
    "\n",
    "    for box in results[0].boxes:\n",
    "        cords = box.xyxy[0].tolist()\n",
    "        cords = [round(x) for x in cords]\n",
    "        class_id = result.names[box.cls[0].item()]\n",
    "        translated_text = translate_to_arabic(class_id)\n",
    "        expected_text = get_arabic_text(translated_text)\n",
    "\n",
    "        conf = round(box.conf[0].item(), 2)\n",
    "\n",
    "        if conf < 0.5:\n",
    "            continue\n",
    "\n",
    "        text_image = convert_text_to_image(expected_text)\n",
    "        frame_with_text = overlay_text_on_frame(frame_with_text, list(word_combinations.keys()))\n",
    "\n",
    "        if translated_text != \"\":\n",
    "            formed_sentence += translated_text\n",
    "            if len(formed_sentence) >= 2:  # Check if there are at least two characters in the formed sentence\n",
    "                if formed_sentence in combinable_words.values():\n",
    "                    word_combinations[formed_sentence] = True\n",
    "                    formed_sentence = \"\"  # Reset the formed sentence for the next combination\n",
    "                else:\n",
    "                    word_combinations[translated_text] = True\n",
    "                    formed_sentence = \"\"\n",
    "\n",
    "    # Display the modified frame\n",
    "    cv2.imshow(\"Object Detection\", frame_with_text)\n",
    "\n",
    "def process_frames():\n",
    "    ret, frame = cap.read()\n",
    "    if frame.shape[:2] != (800, 600):\n",
    "        frame = cv2.resize(frame, (800, 600))\n",
    "\n",
    "    # Perform object detection and modification on the frame\n",
    "    detect_objects(frame)\n",
    "\n",
    "    if len(word_combinations) > 0:\n",
    "        frame_with_text = overlay_text_on_frame(frame, list(word_combinations.keys()))\n",
    "    else:\n",
    "        frame_with_text = frame\n",
    "\n",
    "    # Display the modified frame\n",
    "    cv2.imshow(\"Object Detection\", frame_with_text)\n",
    "\n",
    "    # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "while True:\n",
    "    if not process_frames():\n",
    "        break\n",
    "\n",
    "# Release the video capture and close the window\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Combine the words from the dictionary\n",
    "combined_words = ' '.join(word_combinations.keys())\n",
    "print(\"Combined Words:\", combined_words)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ed3cef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b17c374",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "import arabic_reshaper\n",
    "import cv2\n",
    "from bidi.algorithm import get_display\n",
    "from ultralytics import YOLO\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "\n",
    "yolo_model = YOLO(\"/Users/mernaziad/Desktop/final_train/runs/detect/train/weights/best.pt\")\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "font_face = cv2.FONT_HERSHEY_SIMPLEX\n",
    "font_color = (255, 255, 255)\n",
    "thickness = 2\n",
    "font_path = \"/Users/mernaziad/PycharmProjects/GraduationProject/arabic_font.ttf\"\n",
    "font_size = 32  # Adjust the font size as needed\n",
    "# Set the font properties\n",
    "font_scale = 1\n",
    "font_thickness = 2\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "translation_dict = {\n",
    "    'ALIF':'أ', \n",
    "    'AYN':'ع', \n",
    "    'Atman lak 7aya sa3eeda' :'أتمنى لك حياة سعيدة', \n",
    "    'BAA':'ب', \n",
    "    'DAD':'ض', \n",
    "    'DELL':'د', \n",
    "    'DHAA':'ظ', \n",
    "    'DHELL':'ذ', \n",
    "    'FAA':'ف', \n",
    "    'GHAYN':'غ', \n",
    "    'HA':'هـ', \n",
    "    'HAA':'ح', \n",
    "    'JEEM':'ج', \n",
    "    'KAAF':'ك', \n",
    "    'KHAA':'خ', \n",
    "    'LAAM':'ل', \n",
    "    'MEEM':'م', \n",
    "    'QAAF':'ق', \n",
    "    'RAA':'ر', \n",
    "    'SAD':'ص', \n",
    "    'SEEN':'س', \n",
    "    'SHEEN':'ش', \n",
    "    'TA':'ت', \n",
    "    'TAA':'ط', \n",
    "    'THA':'ث', \n",
    "    'WAW':'و', \n",
    "    'YA':'ي', \n",
    "    'ZAY':'ز', \n",
    "    'bad':'سيء', \n",
    "    'del':'حذف', \n",
    "    'eqtibas':'اقتباس', \n",
    "    'good':'جيد', \n",
    "    'law sama7t':'لو سمحت', \n",
    "    'merhaba':'مرحبا', \n",
    "    'nothing':'لا شيء', \n",
    "    'o7ebok':'أحبك', \n",
    "    'oraqebak':'أراقبك', \n",
    "    'space':'مسافة', \n",
    "    'you':'أنت', \n",
    "}\n",
    " \n",
    "\n",
    "\n",
    "def translate_to_arabic(text):\n",
    "    if text in translation_dict:\n",
    "        return translation_dict[text]\n",
    "    else:\n",
    "        return text  # إذا لم تكن الكلمة موجودة في القاموس، استخدم النص الأصلي\n",
    "\n",
    "\n",
    "def convert_text_to_image(text, background_color=(0, 0, 0, 0)):\n",
    "    # Load the specified font\n",
    "    font = ImageFont.truetype(font_path, font_size)\n",
    "\n",
    "    # Create a new image with a transparent background\n",
    "    image = Image.new('RGBA', (1, 1), background_color)\n",
    "\n",
    "    # Create a draw object\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    # Calculate the text size\n",
    "    text_width, text_height = draw.textsize(text, font=font)\n",
    "\n",
    "    # Add some padding to the text size\n",
    "    padding = 10\n",
    "    image_width = text_width + padding\n",
    "    image_height = text_height + padding\n",
    "\n",
    "    # Create a new image with the adjusted dimensions and background color\n",
    "    image = Image.new('RGBA', (image_width, image_height), background_color)\n",
    "\n",
    "    # Create a new draw object with the adjusted image\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    # Calculate the position to place the text at the bottom of the image\n",
    "    text_x = (image.width - text_width) // 2\n",
    "    text_y = image.height - text_height - padding\n",
    "\n",
    "    # Draw the text on the image\n",
    "    draw.text((text_x, text_y), text, font=font, fill=font_color)\n",
    "\n",
    "    # Convert the PIL image to RGB mode\n",
    "    image = image.convert(\"RGB\")\n",
    "\n",
    "    # Convert the PIL image to a NumPy array\n",
    "    image_array = np.array(image)\n",
    "\n",
    "    return image_array\n",
    "\n",
    "def get_arabic_text(text):\n",
    "    reshaped_text = arabic_reshaper.reshape(text)\n",
    "    bidi_text = get_display(reshaped_text)\n",
    "    return bidi_text\n",
    "\n",
    "\n",
    "def overlay_text_on_frame(frame, text_image):\n",
    "    padding = 10\n",
    "    y = frame.shape[0] - text_image.shape[0] - padding\n",
    "    x = (frame.shape[1] - text_image.shape[1]) // 2\n",
    "    frame[y:y + text_image.shape[0], x:x + text_image.shape[1]] = text_image\n",
    "    \n",
    "\n",
    "    \n",
    "    return frame\n",
    "\n",
    "def detect_objects(frame):\n",
    "    results = yolo_model.predict(frame)\n",
    "    result = results[0]\n",
    "    frame_with_text = frame\n",
    "    for box in results[0].boxes:\n",
    "        cords = box.xyxy[0].tolist()\n",
    "        cords = [round(x) for x in cords]\n",
    "        class_id = result.names[box.cls[0].item()]\n",
    "        translated_text = translate_to_arabic(class_id)\n",
    "        expected_text = get_arabic_text(translated_text)\n",
    "\n",
    "        conf = round(box.conf[0].item(), 2)\n",
    "        logging.info(\"Object type:{} {}\".format(expected_text, class_id))\n",
    "        logging.info(\"Coordinates: {}\".format(cords))\n",
    "        logging.info(\"Probability: {}\".format(conf))\n",
    "\n",
    "        if conf < 0.5:\n",
    "            return\n",
    "\n",
    "        text_image = convert_text_to_image(expected_text)\n",
    "        frame_with_text = overlay_text_on_frame(frame, text_image)\n",
    "        \n",
    "        \n",
    "    # Display the modified frame\n",
    "    cv2.imshow(\"Object Detection\", frame_with_text)\n",
    "\n",
    "\n",
    "def process_frames():\n",
    "    ret, frame = cap.read()\n",
    "    if frame.shape[:2] != (800, 600):\n",
    "        frame = cv2.resize(frame, (800, 600))\n",
    "    # Perform object detection and modification on the frame\n",
    "    detect_objects(frame)\n",
    "    # Break the loop if 'q' is pressed\n",
    "\n",
    "\n",
    "while True:\n",
    "    process_frames()\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# executor = concurrent.futures.ThreadPoolExecutor(max_workers=4)\n",
    "# # Submit the process_frames function to the executor\n",
    "# executor.submit(process_frames)\n",
    "# # Wait for the 'q' key to be pressed\n",
    "# while cv2.waitKey(1) & 0xFF != ord('q'):\n",
    "#     pass\n",
    "\n",
    "# # Shutdown the executor\n",
    "# executor.shutdown()\n",
    "\n",
    "# Release the video capture and close the window\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29565290",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
