{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653a75fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "import arabic_reshaper\n",
    "import cv2\n",
    "from bidi.algorithm import get_display\n",
    "from ultralytics import YOLO\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "\n",
    "yolo_model = YOLO(\"/Users/mernaziad/Desktop/final_train/runs/detect/train/weights/best.pt\")\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "font_face = cv2.FONT_HERSHEY_SIMPLEX\n",
    "font_color = (255, 255, 255)\n",
    "thickness = 2\n",
    "font_path = \"/Users/mernaziad/PycharmProjects/GraduationProject/arabic_font.ttf\"\n",
    "font_size = 32  # Adjust the font size as needed\n",
    "# Set the font properties\n",
    "font_scale = 1\n",
    "font_thickness = 2\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "translation_dict = {\n",
    "    'ALIF':'أ', \n",
    "    'AYN':'ع', \n",
    "    'Atman lak 7aya sa3eeda' :'أتمنى لك حياة سعيدة', \n",
    "    'BAA':'ب', \n",
    "    'DAD':'ض', \n",
    "    'DELL':'د', \n",
    "    'DHAA':'ظ', \n",
    "    'DHELL':'ذ', \n",
    "    'FAA':'ف', \n",
    "    'GHAYN':'غ', \n",
    "    'HA':'هـ', \n",
    "    'HAA':'ح', \n",
    "    'JEEM':'ج', \n",
    "    'KAAF':'ك', \n",
    "    'KHAA':'خ', \n",
    "    'LAAM':'ل', \n",
    "    'MEEM':'م', \n",
    "    'QAAF':'ق', \n",
    "    'RAA':'ر', \n",
    "    'SAD':'ص', \n",
    "    'SEEN':'س', \n",
    "    'SHEEN':'ش', \n",
    "    'TA':'ت', \n",
    "    'TAA':'ط', \n",
    "    'THA':'ث', \n",
    "    'WAW':'و', \n",
    "    'YA':'ي', \n",
    "    'ZAY':'ز', \n",
    "    'bad':'سيء', \n",
    "    'del':'حذف', \n",
    "    'eqtibas':'اقتباس', \n",
    "    'good':'جيد', \n",
    "    'law sama7t':'لو سمحت', \n",
    "    'merhaba':'مرحبا', \n",
    "    'nothing':'لا شيء', \n",
    "    'o7ebok':'أحبك', \n",
    "    'oraqebak':'أراقبك', \n",
    "    'space':'مسافة', \n",
    "    'you':'أنت', \n",
    "}\n",
    " \n",
    "\n",
    "\n",
    "def translate_to_arabic(text):\n",
    "    if text in translation_dict:\n",
    "        return translation_dict[text]\n",
    "    else:\n",
    "        return text  # إذا لم تكن الكلمة موجودة في القاموس، استخدم النص الأصلي\n",
    "\n",
    "\n",
    "def convert_text_to_image(text, background_color=(0, 0, 0, 0)):\n",
    "    # Load the specified font\n",
    "    font = ImageFont.truetype(font_path, font_size)\n",
    "\n",
    "    # Create a new image with a transparent background\n",
    "    image = Image.new('RGBA', (1, 1), background_color)\n",
    "\n",
    "    # Create a draw object\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    # Calculate the text size\n",
    "    text_width, text_height = draw.textsize(text, font=font)\n",
    "\n",
    "    # Add some padding to the text size\n",
    "    padding = 10\n",
    "    image_width = text_width + padding\n",
    "    image_height = text_height + padding\n",
    "\n",
    "    # Create a new image with the adjusted dimensions and background color\n",
    "    image = Image.new('RGBA', (image_width, image_height), background_color)\n",
    "\n",
    "    # Create a new draw object with the adjusted image\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    # Calculate the position to place the text at the bottom of the image\n",
    "    text_x = (image.width - text_width) // 2\n",
    "    text_y = image.height - text_height - padding\n",
    "\n",
    "    # Draw the text on the image\n",
    "    draw.text((text_x, text_y), text, font=font, fill=font_color)\n",
    "\n",
    "    # Convert the PIL image to RGB mode\n",
    "    image = image.convert(\"RGB\")\n",
    "\n",
    "    # Convert the PIL image to a NumPy array\n",
    "    image_array = np.array(image)\n",
    "\n",
    "    return image_array\n",
    "\n",
    "def get_arabic_text(text):\n",
    "    reshaped_text = arabic_reshaper.reshape(text)\n",
    "    bidi_text = get_display(reshaped_text)\n",
    "    return bidi_text\n",
    "\n",
    "\n",
    "def overlay_text_on_frame(frame, text_image):\n",
    "    padding = 10\n",
    "    y = frame.shape[0] - text_image.shape[0] - padding\n",
    "    x = (frame.shape[1] - text_image.shape[1]) // 2\n",
    "    frame[y:y + text_image.shape[0], x:x + text_image.shape[1]] = text_image\n",
    "    \n",
    "\n",
    "    \n",
    "    return frame\n",
    "\n",
    "def detect_objects(frame):\n",
    "    results = yolo_model.predict(frame)\n",
    "    result = results[0]\n",
    "    frame_with_text = frame\n",
    "    for box in results[0].boxes:\n",
    "        cords = box.xyxy[0].tolist()\n",
    "        cords = [round(x) for x in cords]\n",
    "        class_id = result.names[box.cls[0].item()]\n",
    "        translated_text = translate_to_arabic(class_id)\n",
    "        expected_text = get_arabic_text(translated_text)\n",
    "\n",
    "        conf = round(box.conf[0].item(), 2)\n",
    "        logging.info(\"Object type:{} {}\".format(expected_text, class_id))\n",
    "        logging.info(\"Coordinates: {}\".format(cords))\n",
    "        logging.info(\"Probability: {}\".format(conf))\n",
    "\n",
    "        if conf < 0.5:\n",
    "            return\n",
    "\n",
    "        text_image = convert_text_to_image(expected_text)\n",
    "        frame_with_text = overlay_text_on_frame(frame, text_image)\n",
    "        \n",
    "        \n",
    "    # Display the modified frame\n",
    "    cv2.imshow(\"Object Detection\", frame_with_text)\n",
    "\n",
    "\n",
    "def process_frames():\n",
    "    ret, frame = cap.read()\n",
    "    if frame.shape[:2] != (800, 600):\n",
    "        frame = cv2.resize(frame, (800, 600))\n",
    "    # Perform object detection and modification on the frame\n",
    "    detect_objects(frame)\n",
    "    # Break the loop if 'q' is pressed\n",
    "\n",
    "\n",
    "while True:\n",
    "    process_frames()\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# executor = concurrent.futures.ThreadPoolExecutor(max_workers=2)\n",
    "# # Submit the process_frames function to the executor\n",
    "# executor.submit(process_frames)\n",
    "# # Wait for the 'q' key to be pressed\n",
    "# while cv2.waitKey(1) & 0xFF != ord('q'):\n",
    "#     pass\n",
    "\n",
    "# # Shutdown the executor\n",
    "# executor.shutdown()\n",
    "\n",
    "# Release the video capture and close the window\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b0f7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import concurrent.futures\n",
    "import arabic_reshaper\n",
    "import cv2\n",
    "from bidi.algorithm import get_display\n",
    "from ultralytics import YOLO\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from gtts import gTTS\n",
    "import os\n",
    "\n",
    "yolo_model = YOLO(\"/Users/mernaziad/Desktop/final_train/runs/detect/train/weights/best.pt\")\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "font_face = cv2.FONT_HERSHEY_SIMPLEX\n",
    "font_color = (255, 255, 255)\n",
    "thickness = 2\n",
    "font_path = \"/Users/mernaziad/PycharmProjects/GraduationProject/arabic_font.ttf\"\n",
    "font_size = 32  # Adjust the font size as needed\n",
    "# Set the font properties\n",
    "font_scale = 1\n",
    "font_thickness = 2\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "translation_dict = {\n",
    "    '0': '0',\n",
    "    '1': '1',\n",
    "    '2': '2',\n",
    "    '3': '3',\n",
    "    '4': '4',\n",
    "    '5': '5',\n",
    "    '6': '6',\n",
    "    '7': '7',\n",
    "    '8': '8',\n",
    "    '9': '9',\n",
    "    'ALIF': 'أ',\n",
    "    'AYN': 'ع',\n",
    "    'Atman lak 7aya sa3eeda': 'أتمنى لك حياة سعيدة',\n",
    "    'BAA': 'ب',\n",
    "    'DAD': 'ض',\n",
    "    'DELL': 'د',\n",
    "    'DHAA': 'ظ',\n",
    "    'DHELL': 'ذ',\n",
    "    'FAA': 'ف',\n",
    "    'GHAYN': 'غ',\n",
    "    'HA': 'هـ',\n",
    "    'HAA': 'ح',\n",
    "    'JEEM': 'ج',\n",
    "    'KAAF': 'ك',\n",
    "    'KHAA': 'خ',\n",
    "    'LAAM': 'ل',\n",
    "    'MEEM': 'م',\n",
    "    'QAAF': 'ق',\n",
    "    'RAA': 'ر',\n",
    "    'SAD': 'ص',\n",
    "    'SEEN': 'س',\n",
    "    'SHEEN': 'ش',\n",
    "    'TA': 'ت',\n",
    "    'TAA': 'ط',\n",
    "    'THA': 'ث',\n",
    "    'WAW': 'و',\n",
    "    'YA': 'ي',\n",
    "    'ZAY': 'ز',\n",
    "    'bad': 'سيء',\n",
    "    'del': 'حذف',\n",
    "    'eqtibas': 'اقتباس',\n",
    "    'good': 'جيد',\n",
    "    'law sama7t': 'لو سمحت',\n",
    "    'merhaba': 'مرحبا',\n",
    "    'nothing': 'لا شيء',\n",
    "    'o7ebok': 'أحبك',\n",
    "    'oraqebak': 'أراقبك',\n",
    "    'space': 'مسافة',\n",
    "    'you': 'أنت',\n",
    "}\n",
    "\n",
    "\n",
    "def translate_to_arabic(text):\n",
    "    if text in translation_dict:\n",
    "        return translation_dict[text]\n",
    "    else:\n",
    "        return text  # إذا لم تكن الكلمة موجودة في القاموس، استخدم النص الأصلي\n",
    "\n",
    "\n",
    "def convert_text_to_image(text, background_color=(0, 0, 0, 0)):\n",
    "    # Load the specified font\n",
    "    font = ImageFont.truetype(font_path, font_size)\n",
    "\n",
    "    # Create a new image with a transparent background\n",
    "    image = Image.new('RGBA', (1, 1), background_color)\n",
    "\n",
    "    # Create a draw object\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    # Calculate the text size\n",
    "    text_width, text_height = draw.textsize(text, font=font)\n",
    "\n",
    "    # Add some padding to the text size\n",
    "    padding = 10\n",
    "    image_width = text_width + padding\n",
    "    image_height = text_height + padding\n",
    "\n",
    "    # Create a new image with the adjusted dimensions and background color\n",
    "    image = Image.new('RGBA', (image_width, image_height), background_color)\n",
    "\n",
    "    # Create a new draw object with the adjusted image\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    # Calculate the position to place the text at the bottom of the image\n",
    "    text_x = (image.width - text_width) // 2\n",
    "    text_y = image.height - text_height - padding\n",
    "\n",
    "    # Draw the text on the image\n",
    "    draw.text((text_x, text_y), text, font=font, fill=font_color)\n",
    "\n",
    "    # Convert the PIL image to RGB mode\n",
    "    image = image.convert(\"RGB\")\n",
    "\n",
    "    # Convert the PIL image to a NumPy array\n",
    "    image_array = np.array(image)\n",
    "\n",
    "    return image_array\n",
    "\n",
    "\n",
    "def get_arabic_text(text):\n",
    "    reshaped_text = arabic_reshaper.reshape(text)\n",
    "    bidi_text = get_display(reshaped_text)\n",
    "    return bidi_text\n",
    "\n",
    "\n",
    "def overlay_text_on_frame(frame, text_image):\n",
    "    padding = 10\n",
    "    y = frame.shape[0] - text_image.shape[0] - padding\n",
    "    x = (frame.shape[1] - text_image.shape[1]) // 2\n",
    "    frame[y:y + text_image.shape[0], x:x + text_image.shape[1]] = text_image\n",
    "\n",
    "    return frame\n",
    "\n",
    "\n",
    "def detect_objects(frame):\n",
    "    results = yolo_model.predict(frame)\n",
    "    result = results[0]\n",
    "    frame_with_text = frame\n",
    "    texts_to_speak = []\n",
    "    for box in results[0].boxes:\n",
    "        cords = box.xyxy[0].tolist()\n",
    "        cords = [round(x) for x in cords]\n",
    "        class_id = result.names[box.cls[0].item()]\n",
    "        translated_text = translate_to_arabic(class_id)\n",
    "        expected_text = get_arabic_text(translated_text)\n",
    "\n",
    "        conf = round(box.conf[0].item(), 2)\n",
    "        logging.info(\"Object type:{} {}\".format(expected_text, class_id))\n",
    "        logging.info(\"Coordinates: {}\".format(cords))\n",
    "        logging.info(\"Probability: {}\".format(conf))\n",
    "\n",
    "        if conf < 0.5:\n",
    "            return\n",
    "\n",
    "        text_image = convert_text_to_image(expected_text)\n",
    "        frame_with_text = overlay_text_on_frame(frame, text_image)\n",
    "\n",
    "        # Convert the Arabic text to speech\n",
    "        tts = gTTS(text=translated_text, lang='ar')\n",
    "        audio_file = \"/Users/mernaziad/Desktop/text_to_speech.mp3\"\n",
    "        tts.save(audio_file)\n",
    "\n",
    "        # Play the Arabic text as speech\n",
    "        os.system('mpg123 ' + audio_file)\n",
    "        os.remove(audio_file)\n",
    "\n",
    "        texts_to_speak.append(translated_text)\n",
    "\n",
    "    # Display the modified frame\n",
    "    cv2.imshow(\"Object Detection\", frame_with_text)\n",
    "\n",
    "\n",
    "def process_frames():\n",
    "    ret, frame = cap.read()\n",
    "    if frame.shape[:2] != (800, 600):\n",
    "        frame = cv2.resize(frame, (800, 600))\n",
    "    # Perform object detection and modification on the frame\n",
    "    detect_objects(frame)\n",
    "    # Break the loop if 'q' is pressed\n",
    "\n",
    "\n",
    "while True:\n",
    "    process_frames()\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "# executor = concurrent.futures.ThreadPoolExecutor(max_workers=2)\n",
    "# # Submit the process_frames function to the executor\n",
    "# executor.submit(process_frames)\n",
    "# # Wait for the 'q' key to be pressed\n",
    "# while cv2.waitKey(1) & 0xFF != ord('q'):\n",
    "#     pass\n",
    "\n",
    "# # Shutdown the executor\n",
    "# executor.shutdown()\n",
    "# Release the video capture and close the window\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9036969",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
